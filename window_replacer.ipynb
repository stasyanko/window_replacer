{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "window_replacer.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "D2ZvtfXisfFe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# If you forked the repository, you can replace the link.\n",
        "repo_url = 'https://github.com/stasyanko/window_replacer'\n",
        "\n",
        "# Number of training steps.\n",
        "num_steps = 20000\n",
        "\n",
        "# Number of evaluation steps.\n",
        "num_eval_steps = 50\n",
        "\n",
        "MODELS_CONFIG = {\n",
        "    'ssd_mobilenet_v1': {\n",
        "        'model_name': 'ssd_mobilenet_v1_coco_2018_01_28',\n",
        "        'pipeline_file': 'ssd_mobilenet_v1_coco.config',\n",
        "        'batch_size': 12\n",
        "    },\n",
        "    'faster_rcnn_inception_v2': {\n",
        "        'model_name': 'faster_rcnn_inception_v2_coco_2018_01_28',\n",
        "        'pipeline_file': 'faster_rcnn_inception_v2_pets.config',\n",
        "        'batch_size': 12\n",
        "    },\n",
        "    'rfcn_resnet101': {\n",
        "        'model_name': 'rfcn_resnet101_coco_2018_01_28',\n",
        "        'pipeline_file': 'rfcn_resnet101_pets.config',\n",
        "        'batch_size': 8\n",
        "    }\n",
        "}\n",
        "\n",
        "# Pick the model you want to use\n",
        "# Select a model in `MODELS_CONFIG`.\n",
        "selected_model = 'ssd_mobilenet_v1'\n",
        "\n",
        "# Name of the object detection model to use.\n",
        "MODEL = MODELS_CONFIG[selected_model]['model_name']\n",
        "\n",
        "# Name of the pipline file in tensorflow object detection API.\n",
        "pipeline_file = MODELS_CONFIG[selected_model]['pipeline_file']\n",
        "\n",
        "# Training batch size fits in Colabe's Tesla K80 GPU memory for selected model.\n",
        "batch_size = MODELS_CONFIG[selected_model]['batch_size']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ETnmydC7xvug",
        "colab_type": "code",
        "outputId": "ca644d7a-e478-46f0-f515-01b10c8d1410",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        }
      },
      "source": [
        "import os\n",
        "from getpass import getpass\n",
        "\n",
        "%cd /content\n",
        "\n",
        "repo_dir_path = os.path.abspath(os.path.join('.', os.path.basename(repo_url)))\n",
        "\n",
        "user = getpass('user')\n",
        "password = getpass('password')\n",
        "os.environ['GITHUB_AUTH'] = user + ':' + password\n",
        "os.environ['GITHUB_USER'] = user\n",
        "\n",
        "!git clone https://$GITHUB_AUTH@github.com/$GITHUB_USER/window_replacer.git\n",
        "\n",
        "!git clone {repo_url}\n",
        "%cd {repo_dir_path}\n",
        "!git pull"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "user··········\n",
            "password··········\n",
            "Cloning into 'window_replacer'...\n",
            "remote: Enumerating objects: 176, done.\u001b[K\n",
            "remote: Counting objects: 100% (176/176), done.\u001b[K\n",
            "remote: Compressing objects: 100% (127/127), done.\u001b[K\n",
            "remote: Total 176 (delta 48), reused 174 (delta 46), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (176/176), 23.46 MiB | 11.38 MiB/s, done.\n",
            "Resolving deltas: 100% (48/48), done.\n",
            "fatal: destination path 'window_replacer' already exists and is not an empty directory.\n",
            "/content/window_replacer\n",
            "Already up to date.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sU31zjgHy_m7",
        "colab_type": "code",
        "outputId": "aebe9554-d576-40f5-a83b-f1cb41e1f0be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 991
        }
      },
      "source": [
        "%cd /content\n",
        "\n",
        "!git clone --quiet https://github.com/tensorflow/models.git\n",
        "\n",
        "!apt-get install -qq protobuf-compiler python-pil python-lxml python-tk\n",
        "\n",
        "!pip install -q Cython contextlib2 pillow lxml matplotlib\n",
        "\n",
        "!pip install -q pycocotools\n",
        "\n",
        "%run object_detection/builders/model_builder_test.py\n",
        "\n",
        "%cd /content/models/research\n",
        "!protoc object_detection/protos/*.proto --python_out=.\n",
        "\n",
        "import os\n",
        "os.environ['PYTHONPATH'] += ':/content/models/research/:/content/models/research/slim/'\n",
        "\n",
        "!python object_detection/builders/model_builder_test.py"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0727 08:02:32.349614 140635306858368 execution.py:622] File `'object_detection/builders/model_builder_test.py'` not found.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/models/research\n",
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0727 08:02:37.393454 140648373208960 lazy_loader.py:50] \n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "W0727 08:02:37.720754 140648373208960 deprecation_wrapper.py:119] From /content/models/research/slim/nets/inception_resnet_v2.py:373: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
            "\n",
            "W0727 08:02:37.774584 140648373208960 deprecation_wrapper.py:119] From /content/models/research/slim/nets/mobilenet/mobilenet.py:397: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
            "\n",
            "Running tests under Python 3.6.8: /usr/bin/python3\n",
            "[ RUN      ] ModelBuilderTest.test_create_faster_rcnn_model_from_config_with_example_miner\n",
            "[       OK ] ModelBuilderTest.test_create_faster_rcnn_model_from_config_with_example_miner\n",
            "[ RUN      ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
            "[       OK ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
            "[ RUN      ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
            "[       OK ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
            "[ RUN      ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
            "[       OK ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
            "[ RUN      ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
            "[       OK ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
            "[ RUN      ] ModelBuilderTest.test_create_rfcn_model_from_config\n",
            "[       OK ] ModelBuilderTest.test_create_rfcn_model_from_config\n",
            "[ RUN      ] ModelBuilderTest.test_create_ssd_fpn_model_from_config\n",
            "[       OK ] ModelBuilderTest.test_create_ssd_fpn_model_from_config\n",
            "[ RUN      ] ModelBuilderTest.test_create_ssd_models_from_config\n",
            "[       OK ] ModelBuilderTest.test_create_ssd_models_from_config\n",
            "[ RUN      ] ModelBuilderTest.test_invalid_faster_rcnn_batchnorm_update\n",
            "[       OK ] ModelBuilderTest.test_invalid_faster_rcnn_batchnorm_update\n",
            "[ RUN      ] ModelBuilderTest.test_invalid_first_stage_nms_iou_threshold\n",
            "[       OK ] ModelBuilderTest.test_invalid_first_stage_nms_iou_threshold\n",
            "[ RUN      ] ModelBuilderTest.test_invalid_model_config_proto\n",
            "[       OK ] ModelBuilderTest.test_invalid_model_config_proto\n",
            "[ RUN      ] ModelBuilderTest.test_invalid_second_stage_batch_size\n",
            "[       OK ] ModelBuilderTest.test_invalid_second_stage_batch_size\n",
            "[ RUN      ] ModelBuilderTest.test_session\n",
            "[  SKIPPED ] ModelBuilderTest.test_session\n",
            "[ RUN      ] ModelBuilderTest.test_unknown_faster_rcnn_feature_extractor\n",
            "[       OK ] ModelBuilderTest.test_unknown_faster_rcnn_feature_extractor\n",
            "[ RUN      ] ModelBuilderTest.test_unknown_meta_architecture\n",
            "[       OK ] ModelBuilderTest.test_unknown_meta_architecture\n",
            "[ RUN      ] ModelBuilderTest.test_unknown_ssd_feature_extractor\n",
            "[       OK ] ModelBuilderTest.test_unknown_ssd_feature_extractor\n",
            "----------------------------------------------------------------------\n",
            "Ran 16 tests in 0.148s\n",
            "\n",
            "OK (skipped=1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HWBBrlWL0Iht",
        "colab_type": "code",
        "outputId": "393e291f-33d3-4232-d1bf-6fd7e33bac5a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        }
      },
      "source": [
        "%cd {repo_dir_path}\n",
        "\n",
        "!python xml_to_csv.py -i data/images/train -o data/annotations/train_labels.csv -l data/annotations\n",
        "\n",
        "# Convert test folder annotation xml files to a single csv.\n",
        "!python xml_to_csv.py -i data/images/test -o data/annotations/test_labels.csv\n",
        "\n",
        "# Generate `train.record`\n",
        "!python generate_tfrecord.py --csv_input=data/annotations/train_labels.csv --output_path=data/annotations/train.record --img_path=data/images/train --label_map data/annotations/label_map.pbtxt\n",
        "\n",
        "# Generate `test.record`\n",
        "!python generate_tfrecord.py --csv_input=data/annotations/test_labels.csv --output_path=data/annotations/test.record --img_path=data/images/test --label_map data/annotations/label_map.pbtxt"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/window_replacer\n",
            "Successfully converted xml to csv.\n",
            "Generate `data/annotations/label_map.pbtxt`\n",
            "Successfully converted xml to csv.\n",
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0727 08:05:08.449929 139785437742976 deprecation_wrapper.py:119] From generate_tfrecord.py:134: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
            "\n",
            "W0727 08:05:08.450552 139785437742976 deprecation_wrapper.py:119] From generate_tfrecord.py:107: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
            "\n",
            "W0727 08:05:08.463620 139785437742976 deprecation_wrapper.py:119] From /content/models/research/object_detection/utils/label_map_util.py:137: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "Successfully created the TFRecords: /content/window_replacer/data/annotations/train.record\n",
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0727 08:05:12.026696 140409886779264 deprecation_wrapper.py:119] From generate_tfrecord.py:134: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
            "\n",
            "W0727 08:05:12.027292 140409886779264 deprecation_wrapper.py:119] From generate_tfrecord.py:107: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
            "\n",
            "W0727 08:05:12.037451 140409886779264 deprecation_wrapper.py:119] From /content/models/research/object_detection/utils/label_map_util.py:137: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "Successfully created the TFRecords: /content/window_replacer/data/annotations/test.record\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RnCzTknP06PP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_record_fname = '/content/window_replacer/data/annotations/test.record'\n",
        "train_record_fname = '/content/window_replacer/data/annotations/train.record'\n",
        "label_map_pbtxt_fname = '/content/window_replacer/data/annotations/label_map.pbtxt'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bq9GekJd1AuK",
        "colab_type": "code",
        "outputId": "710121dd-6e3a-453c-fe49-31094e0eb8b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "%cd /content/models/research\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "import glob\n",
        "import urllib.request\n",
        "import tarfile\n",
        "MODEL_FILE = MODEL + '.tar.gz'\n",
        "DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/'\n",
        "DEST_DIR = '/content/models/research/pretrained_model'\n",
        "\n",
        "if not (os.path.exists(MODEL_FILE)):\n",
        "    urllib.request.urlretrieve(DOWNLOAD_BASE + MODEL_FILE, MODEL_FILE)\n",
        "\n",
        "tar = tarfile.open(MODEL_FILE)\n",
        "tar.extractall()\n",
        "tar.close()\n",
        "\n",
        "os.remove(MODEL_FILE)\n",
        "if (os.path.exists(DEST_DIR)):\n",
        "    shutil.rmtree(DEST_DIR)\n",
        "os.rename(MODEL, DEST_DIR)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/models/research\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pggcnf6U1HFi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "outputId": "d0278059-ecb0-4b88-8105-54d5bbcd1eb1"
      },
      "source": [
        "!echo {DEST_DIR}\n",
        "!ls -alh {DEST_DIR}"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/models/research/pretrained_model\n",
            "total 57M\n",
            "drwxr-xr-x  3 345018 5000 4.0K Feb  1  2018 .\n",
            "drwxr-xr-x 71 root   root 4.0K Jul 27 08:05 ..\n",
            "-rw-r--r--  1 345018 5000   77 Feb  1  2018 checkpoint\n",
            "-rw-r--r--  1 345018 5000  28M Feb  1  2018 frozen_inference_graph.pb\n",
            "-rw-r--r--  1 345018 5000  27M Feb  1  2018 model.ckpt.data-00000-of-00001\n",
            "-rw-r--r--  1 345018 5000 8.8K Feb  1  2018 model.ckpt.index\n",
            "-rw-r--r--  1 345018 5000 2.9M Feb  1  2018 model.ckpt.meta\n",
            "-rw-r--r--  1 345018 5000 4.1K Feb  1  2018 pipeline.config\n",
            "drwxr-xr-x  3 345018 5000 4.0K Feb  1  2018 saved_model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ML1oFVsZ1Mk4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c45ff3fa-2c9a-470c-9a8a-152e57ea382b"
      },
      "source": [
        "fine_tune_checkpoint = os.path.join(DEST_DIR, \"model.ckpt\")\n",
        "fine_tune_checkpoint"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/models/research/pretrained_model/model.ckpt'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmmJX5Tk1Tk4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "pipeline_fname = os.path.join('/content/models/research/object_detection/samples/configs/', pipeline_file)\n",
        "\n",
        "assert os.path.isfile(pipeline_fname), '`{}` not exist'.format(pipeline_fname)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S5CA9qdH1Xbx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_num_classes(pbtxt_fname):\n",
        "    from object_detection.utils import label_map_util\n",
        "    label_map = label_map_util.load_labelmap(pbtxt_fname)\n",
        "    categories = label_map_util.convert_label_map_to_categories(\n",
        "        label_map, max_num_classes=90, use_display_name=True)\n",
        "    category_index = label_map_util.create_category_index(categories)\n",
        "    return len(category_index.keys())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fsI9pJgJ1aEG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "5e4f28d3-f7a5-48e8-8351-cbe37f014444"
      },
      "source": [
        "import re\n",
        "\n",
        "num_classes = get_num_classes(label_map_pbtxt_fname)\n",
        "with open(pipeline_fname) as f:\n",
        "    s = f.read()\n",
        "with open(pipeline_fname, 'w') as f:\n",
        "    \n",
        "    # fine_tune_checkpoint\n",
        "    s = re.sub('fine_tune_checkpoint: \".*?\"',\n",
        "               'fine_tune_checkpoint: \"{}\"'.format(fine_tune_checkpoint), s)\n",
        "    \n",
        "    # tfrecord files train and test.\n",
        "    s = re.sub(\n",
        "        '(input_path: \".*?)(train.record)(.*?\")', 'input_path: \"{}\"'.format(train_record_fname), s)\n",
        "    s = re.sub(\n",
        "        '(input_path: \".*?)(val.record)(.*?\")', 'input_path: \"{}\"'.format(test_record_fname), s)\n",
        "\n",
        "    # label_map_path\n",
        "    s = re.sub(\n",
        "        'label_map_path: \".*?\"', 'label_map_path: \"{}\"'.format(label_map_pbtxt_fname), s)\n",
        "\n",
        "    # Set training batch_size.\n",
        "    s = re.sub('batch_size: [0-9]+',\n",
        "               'batch_size: {}'.format(batch_size), s)\n",
        "\n",
        "    # Set training steps, num_steps\n",
        "    s = re.sub('num_steps: [0-9]+',\n",
        "               'num_steps: {}'.format(num_steps), s)\n",
        "    \n",
        "    # Set number of classes num_classes.\n",
        "    s = re.sub('num_classes: [0-9]+',\n",
        "               'num_classes: {}'.format(num_classes), s)\n",
        "    f.write(s)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0727 08:17:20.796864 140635306858368 deprecation_wrapper.py:119] From /content/window_replacer/models/research/object_detection/utils/label_map_util.py:137: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KJP3JTdh15UD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5513c86a-b119-4f8c-a862-497f87cbc0c7"
      },
      "source": [
        "!cat {pipeline_fname}"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# SSD with Mobilenet v1 configuration for MSCOCO Dataset.\n",
            "# Users should configure the fine_tune_checkpoint field in the train config as\n",
            "# well as the label_map_path and input_path fields in the train_input_reader and\n",
            "# eval_input_reader. Search for \"PATH_TO_BE_CONFIGURED\" to find the fields that\n",
            "# should be configured.\n",
            "\n",
            "model {\n",
            "  ssd {\n",
            "    num_classes: 1\n",
            "    box_coder {\n",
            "      faster_rcnn_box_coder {\n",
            "        y_scale: 10.0\n",
            "        x_scale: 10.0\n",
            "        height_scale: 5.0\n",
            "        width_scale: 5.0\n",
            "      }\n",
            "    }\n",
            "    matcher {\n",
            "      argmax_matcher {\n",
            "        matched_threshold: 0.5\n",
            "        unmatched_threshold: 0.5\n",
            "        ignore_thresholds: false\n",
            "        negatives_lower_than_unmatched: true\n",
            "        force_match_for_each_row: true\n",
            "      }\n",
            "    }\n",
            "    similarity_calculator {\n",
            "      iou_similarity {\n",
            "      }\n",
            "    }\n",
            "    anchor_generator {\n",
            "      ssd_anchor_generator {\n",
            "        num_layers: 6\n",
            "        min_scale: 0.2\n",
            "        max_scale: 0.95\n",
            "        aspect_ratios: 1.0\n",
            "        aspect_ratios: 2.0\n",
            "        aspect_ratios: 0.5\n",
            "        aspect_ratios: 3.0\n",
            "        aspect_ratios: 0.3333\n",
            "      }\n",
            "    }\n",
            "    image_resizer {\n",
            "      fixed_shape_resizer {\n",
            "        height: 300\n",
            "        width: 300\n",
            "      }\n",
            "    }\n",
            "    box_predictor {\n",
            "      convolutional_box_predictor {\n",
            "        min_depth: 0\n",
            "        max_depth: 0\n",
            "        num_layers_before_predictor: 0\n",
            "        use_dropout: false\n",
            "        dropout_keep_probability: 0.8\n",
            "        kernel_size: 1\n",
            "        box_code_size: 4\n",
            "        apply_sigmoid_to_scores: false\n",
            "        conv_hyperparams {\n",
            "          activation: RELU_6,\n",
            "          regularizer {\n",
            "            l2_regularizer {\n",
            "              weight: 0.00004\n",
            "            }\n",
            "          }\n",
            "          initializer {\n",
            "            truncated_normal_initializer {\n",
            "              stddev: 0.03\n",
            "              mean: 0.0\n",
            "            }\n",
            "          }\n",
            "          batch_norm {\n",
            "            train: true,\n",
            "            scale: true,\n",
            "            center: true,\n",
            "            decay: 0.9997,\n",
            "            epsilon: 0.001,\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "    feature_extractor {\n",
            "      type: 'ssd_mobilenet_v1'\n",
            "      min_depth: 16\n",
            "      depth_multiplier: 1.0\n",
            "      conv_hyperparams {\n",
            "        activation: RELU_6,\n",
            "        regularizer {\n",
            "          l2_regularizer {\n",
            "            weight: 0.00004\n",
            "          }\n",
            "        }\n",
            "        initializer {\n",
            "          truncated_normal_initializer {\n",
            "            stddev: 0.03\n",
            "            mean: 0.0\n",
            "          }\n",
            "        }\n",
            "        batch_norm {\n",
            "          train: true,\n",
            "          scale: true,\n",
            "          center: true,\n",
            "          decay: 0.9997,\n",
            "          epsilon: 0.001,\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "    loss {\n",
            "      classification_loss {\n",
            "        weighted_sigmoid {\n",
            "        }\n",
            "      }\n",
            "      localization_loss {\n",
            "        weighted_smooth_l1 {\n",
            "        }\n",
            "      }\n",
            "      hard_example_miner {\n",
            "        num_hard_examples: 3000\n",
            "        iou_threshold: 0.99\n",
            "        loss_type: CLASSIFICATION\n",
            "        max_negatives_per_positive: 3\n",
            "        min_negatives_per_image: 0\n",
            "      }\n",
            "      classification_weight: 1.0\n",
            "      localization_weight: 1.0\n",
            "    }\n",
            "    normalize_loss_by_num_matches: true\n",
            "    post_processing {\n",
            "      batch_non_max_suppression {\n",
            "        score_threshold: 1e-8\n",
            "        iou_threshold: 0.6\n",
            "        max_detections_per_class: 100\n",
            "        max_total_detections: 100\n",
            "      }\n",
            "      score_converter: SIGMOID\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n",
            "train_config: {\n",
            "  batch_size: 12\n",
            "  optimizer {\n",
            "    rms_prop_optimizer: {\n",
            "      learning_rate: {\n",
            "        exponential_decay_learning_rate {\n",
            "          initial_learning_rate: 0.004\n",
            "          decay_steps: 800720\n",
            "          decay_factor: 0.95\n",
            "        }\n",
            "      }\n",
            "      momentum_optimizer_value: 0.9\n",
            "      decay: 0.9\n",
            "      epsilon: 1.0\n",
            "    }\n",
            "  }\n",
            "  fine_tune_checkpoint: \"/content/models/research/pretrained_model/model.ckpt\"\n",
            "  from_detection_checkpoint: true\n",
            "  # Note: The below line limits the training process to 200K steps, which we\n",
            "  # empirically found to be sufficient enough to train the pets dataset. This\n",
            "  # effectively bypasses the learning rate schedule (the learning rate will\n",
            "  # never decay). Remove the below line to train indefinitely.\n",
            "  num_steps: 20000\n",
            "  data_augmentation_options {\n",
            "    random_horizontal_flip {\n",
            "    }\n",
            "  }\n",
            "  data_augmentation_options {\n",
            "    ssd_random_crop {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n",
            "train_input_reader: {\n",
            "  tf_record_input_reader {\n",
            "    input_path: \"/content/window_replacer/data/annotations/train.record\"\n",
            "  }\n",
            "  label_map_path: \"/content/window_replacer/data/annotations/label_map.pbtxt\"\n",
            "}\n",
            "\n",
            "eval_config: {\n",
            "  num_examples: 8000\n",
            "  # Note: The below line limits the evaluation process to 10 evaluations.\n",
            "  # Remove the below line to evaluate indefinitely.\n",
            "  max_evals: 10\n",
            "}\n",
            "\n",
            "eval_input_reader: {\n",
            "  tf_record_input_reader {\n",
            "    input_path: \"/content/window_replacer/data/annotations/test.record\"\n",
            "  }\n",
            "  label_map_path: \"/content/window_replacer/data/annotations/label_map.pbtxt\"\n",
            "  shuffle: false\n",
            "  num_readers: 1\n",
            "}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5VRvex6o198O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_dir = 'training/'\n",
        "# Optionally remove content in output model directory to fresh start.\n",
        "!rm -rf {model_dir}\n",
        "os.makedirs(model_dir, exist_ok=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Mos8Mpn6nJ2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "cf8d8fc8-abb3-44cd-823a-c9f4585f56a7"
      },
      "source": [
        "!python /content/models/research/object_detection/model_main.py \\\n",
        "    --pipeline_config_path={pipeline_fname} \\\n",
        "    --model_dir={model_dir} \\\n",
        "    --alsologtostderr \\\n",
        "    --num_train_steps={num_steps} \\\n",
        "    --num_eval_steps={num_eval_steps}"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0727 11:01:58.162609 139624873338752 lazy_loader.py:50] \n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "W0727 11:01:58.191035 139624873338752 deprecation_wrapper.py:119] From /content/models/research/slim/nets/inception_resnet_v2.py:373: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
            "\n",
            "W0727 11:01:58.202009 139624873338752 deprecation_wrapper.py:119] From /content/models/research/slim/nets/mobilenet/mobilenet.py:397: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
            "\n",
            "W0727 11:01:58.213330 139624873338752 deprecation_wrapper.py:119] From /content/models/research/object_detection/model_main.py:109: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
            "\n",
            "W0727 11:01:58.214252 139624873338752 deprecation_wrapper.py:119] From /content/models/research/object_detection/utils/config_util.py:102: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "W0727 11:01:58.218699 139624873338752 deprecation_wrapper.py:119] From /content/models/research/object_detection/model_lib.py:616: The name tf.logging.warning is deprecated. Please use tf.compat.v1.logging.warning instead.\n",
            "\n",
            "W0727 11:01:58.218839 139624873338752 model_lib.py:617] Forced number of epochs for all eval validations to be 1.\n",
            "W0727 11:01:58.218952 139624873338752 deprecation_wrapper.py:119] From /content/models/research/object_detection/utils/config_util.py:488: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n",
            "I0727 11:01:58.219024 139624873338752 config_util.py:488] Maybe overwriting train_steps: 30000\n",
            "I0727 11:01:58.219094 139624873338752 config_util.py:488] Maybe overwriting use_bfloat16: False\n",
            "I0727 11:01:58.219161 139624873338752 config_util.py:488] Maybe overwriting sample_1_of_n_eval_examples: 1\n",
            "I0727 11:01:58.219221 139624873338752 config_util.py:488] Maybe overwriting eval_num_epochs: 1\n",
            "I0727 11:01:58.219278 139624873338752 config_util.py:488] Maybe overwriting load_pretrained: True\n",
            "I0727 11:01:58.219336 139624873338752 config_util.py:498] Ignoring config override key: load_pretrained\n",
            "W0727 11:01:58.219441 139624873338752 model_lib.py:633] Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
            "I0727 11:01:58.219515 139624873338752 model_lib.py:668] create_estimator_and_inputs: use_tpu False, export_to_tpu False\n",
            "I0727 11:01:58.220040 139624873338752 estimator.py:209] Using config: {'_model_dir': 'training/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7efca4b30470>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "W0727 11:01:58.220229 139624873338752 model_fn.py:630] Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x7efca4abd268>) includes params argument, but params are not passed to Estimator.\n",
            "I0727 11:01:58.221307 139624873338752 estimator_training.py:186] Not using Distribute Coordinator.\n",
            "I0727 11:01:58.221480 139624873338752 training.py:612] Running training and evaluation locally (non-distributed).\n",
            "I0727 11:01:58.221714 139624873338752 training.py:700] Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
            "W0727 11:01:58.231076 139624873338752 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "W0727 11:01:58.244404 139624873338752 deprecation_wrapper.py:119] From /content/models/research/object_detection/data_decoders/tf_example_decoder.py:182: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n",
            "\n",
            "W0727 11:01:58.244673 139624873338752 deprecation_wrapper.py:119] From /content/models/research/object_detection/data_decoders/tf_example_decoder.py:197: The name tf.VarLenFeature is deprecated. Please use tf.io.VarLenFeature instead.\n",
            "\n",
            "W0727 11:01:58.258291 139624873338752 deprecation_wrapper.py:119] From /content/models/research/object_detection/builders/dataset_builder.py:64: The name tf.gfile.Glob is deprecated. Please use tf.io.gfile.glob instead.\n",
            "\n",
            "W0727 11:01:58.259214 139624873338752 dataset_builder.py:72] num_readers has been reduced to 1 to match input file shards.\n",
            "W0727 11:01:58.264662 139624873338752 deprecation.py:323] From /content/models/research/object_detection/builders/dataset_builder.py:86: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.experimental.parallel_interleave(...)`.\n",
            "W0727 11:01:58.264863 139624873338752 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/data/python/ops/interleave_ops.py:77: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n",
            "W0727 11:01:58.289442 139624873338752 deprecation.py:323] From /content/models/research/object_detection/builders/dataset_builder.py:155: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "W0727 11:01:58.462034 139624873338752 deprecation_wrapper.py:119] From /content/models/research/object_detection/utils/ops.py:491: The name tf.is_nan is deprecated. Please use tf.math.is_nan instead.\n",
            "\n",
            "W0727 11:01:58.466114 139624873338752 deprecation.py:323] From /content/models/research/object_detection/utils/ops.py:493: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0727 11:01:58.513630 139624873338752 deprecation_wrapper.py:119] From /content/models/research/object_detection/core/preprocessor.py:626: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0727 11:01:58.575665 139624873338752 deprecation.py:323] From /content/models/research/object_detection/core/preprocessor.py:196: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
            "W0727 11:01:59.585134 139624873338752 deprecation_wrapper.py:119] From /content/models/research/object_detection/core/preprocessor.py:2660: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\n",
            "\n",
            "W0727 11:02:00.175443 139624873338752 deprecation.py:323] From /content/models/research/object_detection/builders/dataset_builder.py:158: batch_and_drop_remainder (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.batch(..., drop_remainder=True)`.\n",
            "I0727 11:02:00.189852 139624873338752 estimator.py:1145] Calling model_fn.\n",
            "I0727 11:02:02.961950 139624873338752 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "I0727 11:02:03.001971 139624873338752 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "I0727 11:02:03.041998 139624873338752 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "I0727 11:02:03.080947 139624873338752 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "I0727 11:02:03.119758 139624873338752 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "I0727 11:02:03.160096 139624873338752 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "W0727 11:02:03.205817 139624873338752 deprecation_wrapper.py:119] From /content/models/research/object_detection/utils/variables_helper.py:139: The name tf.train.NewCheckpointReader is deprecated. Please use tf.compat.v1.train.NewCheckpointReader instead.\n",
            "\n",
            "W0727 11:02:03.211906 139624873338752 deprecation_wrapper.py:119] From /content/models/research/object_detection/model_lib.py:345: The name tf.train.init_from_checkpoint is deprecated. Please use tf.compat.v1.train.init_from_checkpoint instead.\n",
            "\n",
            "W0727 11:02:06.431701 139624873338752 deprecation_wrapper.py:119] From /content/models/research/object_detection/meta_architectures/ssd_meta_arch.py:1089: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
            "\n",
            "W0727 11:02:06.438736 139624873338752 deprecation_wrapper.py:119] From /content/models/research/object_detection/core/losses.py:177: The name tf.losses.huber_loss is deprecated. Please use tf.compat.v1.losses.huber_loss instead.\n",
            "\n",
            "W0727 11:02:06.440218 139624873338752 deprecation_wrapper.py:119] From /content/models/research/object_detection/core/losses.py:183: The name tf.losses.Reduction is deprecated. Please use tf.compat.v1.losses.Reduction instead.\n",
            "\n",
            "W0727 11:02:06.816079 139624873338752 deprecation_wrapper.py:119] From /content/models/research/object_detection/model_lib.py:372: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n",
            "\n",
            "W0727 11:02:06.816401 139624873338752 deprecation_wrapper.py:119] From /content/models/research/object_detection/utils/learning_schedules.py:66: The name tf.train.exponential_decay is deprecated. Please use tf.compat.v1.train.exponential_decay instead.\n",
            "\n",
            "W0727 11:02:06.826816 139624873338752 deprecation_wrapper.py:119] From /content/models/research/object_detection/builders/optimizer_builder.py:47: The name tf.train.RMSPropOptimizer is deprecated. Please use tf.compat.v1.train.RMSPropOptimizer instead.\n",
            "\n",
            "W0727 11:02:08.627924 139624873338752 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/rmsprop.py:119: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "I0727 11:02:13.546770 139624873338752 estimator.py:1147] Done calling model_fn.\n",
            "I0727 11:02:13.548322 139624873338752 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\n",
            "I0727 11:02:16.447906 139624873338752 monitored_session.py:240] Graph was finalized.\n",
            "2019-07-27 11:02:16.453281: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200000000 Hz\n",
            "2019-07-27 11:02:16.453551: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x10370380 executing computations on platform Host. Devices:\n",
            "2019-07-27 11:02:16.453584: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\n",
            "2019-07-27 11:02:16.470518: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1\n",
            "2019-07-27 11:02:16.645072: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-27 11:02:16.645606: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x10370700 executing computations on platform CUDA. Devices:\n",
            "2019-07-27 11:02:16.645637: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "2019-07-27 11:02:16.645903: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-27 11:02:16.646361: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2019-07-27 11:02:16.646697: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
            "2019-07-27 11:02:16.647920: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
            "2019-07-27 11:02:16.649187: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\n",
            "2019-07-27 11:02:16.649546: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\n",
            "2019-07-27 11:02:16.651045: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2019-07-27 11:02:16.652083: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2019-07-27 11:02:16.655485: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
            "2019-07-27 11:02:16.655612: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-27 11:02:16.656081: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-27 11:02:16.656501: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
            "2019-07-27 11:02:16.656565: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
            "2019-07-27 11:02:16.657662: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-07-27 11:02:16.657691: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 \n",
            "2019-07-27 11:02:16.657703: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N \n",
            "2019-07-27 11:02:16.658024: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-27 11:02:16.658461: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-27 11:02:16.658821: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:40] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2019-07-27 11:02:16.658868: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14202 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "W0727 11:02:16.660150 139624873338752 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "I0727 11:02:16.661469 139624873338752 saver.py:1280] Restoring parameters from training/model.ckpt-20000\n",
            "W0727 11:02:18.371352 139624873338752 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1066: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file utilities to get mtimes.\n",
            "2019-07-27 11:02:19.008967: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.\n",
            "I0727 11:02:19.085222 139624873338752 session_manager.py:500] Running local_init_op.\n",
            "I0727 11:02:19.285424 139624873338752 session_manager.py:502] Done running local_init_op.\n",
            "I0727 11:02:27.160557 139624873338752 basic_session_run_hooks.py:606] Saving checkpoints for 20000 into training/model.ckpt.\n",
            "2019-07-27 11:02:33.745993: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
            "I0727 11:02:37.640637 139624873338752 basic_session_run_hooks.py:262] loss = 1.0781372, step = 20000\n",
            "I0727 11:03:26.733281 139624873338752 basic_session_run_hooks.py:692] global_step/sec: 2.03693\n",
            "I0727 11:03:26.734760 139624873338752 basic_session_run_hooks.py:260] loss = 2.0077639, step = 20100 (49.094 sec)\n",
            "I0727 11:04:13.127061 139624873338752 basic_session_run_hooks.py:692] global_step/sec: 2.15546\n",
            "I0727 11:04:13.128113 139624873338752 basic_session_run_hooks.py:260] loss = 1.5482478, step = 20200 (46.393 sec)\n",
            "I0727 11:04:58.829085 139624873338752 basic_session_run_hooks.py:692] global_step/sec: 2.18809\n",
            "I0727 11:04:58.830293 139624873338752 basic_session_run_hooks.py:260] loss = 1.3333936, step = 20300 (45.702 sec)\n",
            "I0727 11:05:45.264041 139624873338752 basic_session_run_hooks.py:692] global_step/sec: 2.15355\n",
            "I0727 11:05:45.265238 139624873338752 basic_session_run_hooks.py:260] loss = 1.2335092, step = 20400 (46.435 sec)\n",
            "I0727 11:06:31.948196 139624873338752 basic_session_run_hooks.py:692] global_step/sec: 2.14206\n",
            "I0727 11:06:31.949336 139624873338752 basic_session_run_hooks.py:260] loss = 1.5710355, step = 20500 (46.684 sec)\n",
            "I0727 11:07:17.901953 139624873338752 basic_session_run_hooks.py:692] global_step/sec: 2.1761\n",
            "I0727 11:07:17.903271 139624873338752 basic_session_run_hooks.py:260] loss = 1.8538278, step = 20600 (45.954 sec)\n",
            "I0727 11:08:04.135688 139624873338752 basic_session_run_hooks.py:692] global_step/sec: 2.16292\n",
            "I0727 11:08:04.136873 139624873338752 basic_session_run_hooks.py:260] loss = 1.2258731, step = 20700 (46.234 sec)\n",
            "I0727 11:08:51.220764 139624873338752 basic_session_run_hooks.py:692] global_step/sec: 2.12382\n",
            "I0727 11:08:51.222054 139624873338752 basic_session_run_hooks.py:260] loss = 1.0630163, step = 20800 (47.085 sec)\n",
            "I0727 11:09:37.924686 139624873338752 basic_session_run_hooks.py:692] global_step/sec: 2.14115\n",
            "I0727 11:09:37.926260 139624873338752 basic_session_run_hooks.py:260] loss = 1.2937152, step = 20900 (46.704 sec)\n",
            "I0727 11:10:24.044864 139624873338752 basic_session_run_hooks.py:692] global_step/sec: 2.16825\n",
            "I0727 11:10:24.046427 139624873338752 basic_session_run_hooks.py:260] loss = 1.4773791, step = 21000 (46.120 sec)\n",
            "I0727 11:11:10.400095 139624873338752 basic_session_run_hooks.py:692] global_step/sec: 2.15725\n",
            "I0727 11:11:10.401143 139624873338752 basic_session_run_hooks.py:260] loss = 1.274519, step = 21100 (46.355 sec)\n",
            "I0727 11:11:56.457658 139624873338752 basic_session_run_hooks.py:692] global_step/sec: 2.17119\n",
            "I0727 11:11:56.458982 139624873338752 basic_session_run_hooks.py:260] loss = 1.4062715, step = 21200 (46.058 sec)\n",
            "I0727 11:12:29.045086 139624873338752 basic_session_run_hooks.py:606] Saving checkpoints for 21272 into training/model.ckpt.\n",
            "W0727 11:12:29.156074 139624873338752 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:960: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to delete files with this prefix.\n",
            "I0727 11:12:30.999101 139624873338752 estimator.py:1145] Calling model_fn.\n",
            "I0727 11:12:33.122930 139624873338752 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "I0727 11:12:33.161604 139624873338752 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "I0727 11:12:33.200063 139624873338752 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "I0727 11:12:33.237829 139624873338752 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "I0727 11:12:33.276458 139624873338752 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "I0727 11:12:33.316085 139624873338752 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "W0727 11:12:34.120958 139624873338752 deprecation.py:323] From /content/models/research/object_detection/eval_util.py:796: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0727 11:12:34.320480 139624873338752 deprecation.py:323] From /content/models/research/object_detection/utils/visualization_utils.py:498: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "tf.py_func is deprecated in TF V2. Instead, there are two\n",
            "    options available in V2.\n",
            "    - tf.py_function takes a python function which manipulates tf eager\n",
            "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
            "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
            "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
            "    being differentiable using a gradient tape.\n",
            "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
            "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
            "    stateful argument making all functions stateful.\n",
            "    \n",
            "W0727 11:12:34.517538 139624873338752 deprecation_wrapper.py:119] From /content/models/research/object_detection/utils/visualization_utils.py:1010: The name tf.summary.image is deprecated. Please use tf.compat.v1.summary.image instead.\n",
            "\n",
            "W0727 11:12:34.626776 139624873338752 deprecation_wrapper.py:119] From /content/models/research/object_detection/model_lib.py:472: The name tf.metrics.mean is deprecated. Please use tf.compat.v1.metrics.mean instead.\n",
            "\n",
            "I0727 11:12:35.199877 139624873338752 estimator.py:1147] Done calling model_fn.\n",
            "I0727 11:12:35.220561 139624873338752 evaluation.py:255] Starting evaluation at 2019-07-27T11:12:35Z\n",
            "I0727 11:12:35.552389 139624873338752 monitored_session.py:240] Graph was finalized.\n",
            "2019-07-27 11:12:35.553811: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-27 11:12:35.554156: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2019-07-27 11:12:35.554270: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
            "2019-07-27 11:12:35.554298: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
            "2019-07-27 11:12:35.554322: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\n",
            "2019-07-27 11:12:35.554347: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\n",
            "2019-07-27 11:12:35.554375: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2019-07-27 11:12:35.554397: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2019-07-27 11:12:35.554420: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
            "2019-07-27 11:12:35.554501: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-27 11:12:35.554873: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-27 11:12:35.555196: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
            "2019-07-27 11:12:35.555248: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-07-27 11:12:35.555264: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 \n",
            "2019-07-27 11:12:35.555275: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N \n",
            "2019-07-27 11:12:35.555486: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-27 11:12:35.555853: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-27 11:12:35.556176: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14202 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "I0727 11:12:35.557471 139624873338752 saver.py:1280] Restoring parameters from training/model.ckpt-21272\n",
            "I0727 11:12:36.175769 139624873338752 session_manager.py:500] Running local_init_op.\n",
            "I0727 11:12:36.265346 139624873338752 session_manager.py:502] Done running local_init_op.\n",
            "I0727 11:12:38.844925 139623159678720 coco_evaluation.py:205] Performing evaluation on 9 images.\n",
            "creating index...\n",
            "index created!\n",
            "I0727 11:12:38.846311 139623159678720 coco_tools.py:115] Loading and preparing annotation results...\n",
            "I0727 11:12:38.847050 139623159678720 coco_tools.py:137] DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.25s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.148\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.365\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.112\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.114\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.397\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.108\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.231\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.271\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.181\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.630\n",
            "I0727 11:12:39.856522 139624873338752 evaluation.py:275] Finished evaluation at 2019-07-27-11:12:39\n",
            "I0727 11:12:39.856911 139624873338752 estimator.py:2039] Saving dict for global step 21272: DetectionBoxes_Precision/mAP = 0.14820118, DetectionBoxes_Precision/mAP (large) = 0.39722827, DetectionBoxes_Precision/mAP (medium) = 0.11391957, DetectionBoxes_Precision/mAP (small) = 0.0, DetectionBoxes_Precision/mAP@.50IOU = 0.36496705, DetectionBoxes_Precision/mAP@.75IOU = 0.112488724, DetectionBoxes_Recall/AR@1 = 0.108333334, DetectionBoxes_Recall/AR@10 = 0.23125, DetectionBoxes_Recall/AR@100 = 0.27083334, DetectionBoxes_Recall/AR@100 (large) = 0.63, DetectionBoxes_Recall/AR@100 (medium) = 0.18108109, DetectionBoxes_Recall/AR@100 (small) = 0.0, Loss/classification_loss = 11.272416, Loss/localization_loss = 1.4272459, Loss/regularization_loss = 0.3440244, Loss/total_loss = 13.043687, global_step = 21272, learning_rate = 0.004, loss = 13.043687\n",
            "I0727 11:12:40.565325 139624873338752 estimator.py:2099] Saving 'checkpoint_path' summary for global step 21272: training/model.ckpt-21272\n",
            "I0727 11:12:54.368036 139624873338752 basic_session_run_hooks.py:692] global_step/sec: 1.72681\n",
            "I0727 11:12:54.369164 139624873338752 basic_session_run_hooks.py:260] loss = 1.6766021, step = 21300 (57.910 sec)\n",
            "I0727 11:13:40.621184 139624873338752 basic_session_run_hooks.py:692] global_step/sec: 2.16202\n",
            "I0727 11:13:40.622204 139624873338752 basic_session_run_hooks.py:260] loss = 1.1970351, step = 21400 (46.253 sec)\n",
            "I0727 11:14:26.508238 139624873338752 basic_session_run_hooks.py:692] global_step/sec: 2.17926\n",
            "I0727 11:14:26.509290 139624873338752 basic_session_run_hooks.py:260] loss = 1.1472428, step = 21500 (45.887 sec)\n",
            "I0727 11:15:12.744865 139624873338752 basic_session_run_hooks.py:692] global_step/sec: 2.16279\n",
            "I0727 11:15:12.745852 139624873338752 basic_session_run_hooks.py:260] loss = 1.6204443, step = 21600 (46.237 sec)\n",
            "I0727 11:15:59.086877 139624873338752 basic_session_run_hooks.py:692] global_step/sec: 2.15787\n",
            "I0727 11:15:59.088068 139624873338752 basic_session_run_hooks.py:260] loss = 1.7178072, step = 21700 (46.342 sec)\n",
            "I0727 11:16:45.518545 139624873338752 basic_session_run_hooks.py:692] global_step/sec: 2.1537\n",
            "I0727 11:16:45.519813 139624873338752 basic_session_run_hooks.py:260] loss = 1.219018, step = 21800 (46.432 sec)\n",
            "I0727 11:17:31.676738 139624873338752 basic_session_run_hooks.py:692] global_step/sec: 2.16646\n",
            "I0727 11:17:31.677964 139624873338752 basic_session_run_hooks.py:260] loss = 1.0004593, step = 21900 (46.158 sec)\n",
            "I0727 11:18:17.964065 139624873338752 basic_session_run_hooks.py:692] global_step/sec: 2.16042\n",
            "I0727 11:18:17.965082 139624873338752 basic_session_run_hooks.py:260] loss = 1.2207205, step = 22000 (46.287 sec)\n",
            "I0727 11:19:03.857425 139624873338752 basic_session_run_hooks.py:692] global_step/sec: 2.17897\n",
            "I0727 11:19:03.858725 139624873338752 basic_session_run_hooks.py:260] loss = 1.5970219, step = 22100 (45.894 sec)\n",
            "I0727 11:19:49.658762 139624873338752 basic_session_run_hooks.py:692] global_step/sec: 2.18334\n",
            "I0727 11:19:49.659852 139624873338752 basic_session_run_hooks.py:260] loss = 1.6753802, step = 22200 (45.801 sec)\n",
            "I0727 11:20:35.551142 139624873338752 basic_session_run_hooks.py:692] global_step/sec: 2.17901\n",
            "I0727 11:20:35.552258 139624873338752 basic_session_run_hooks.py:260] loss = 1.1479676, step = 22300 (45.892 sec)\n",
            "I0727 11:21:21.895588 139624873338752 basic_session_run_hooks.py:692] global_step/sec: 2.15776\n",
            "I0727 11:21:21.897236 139624873338752 basic_session_run_hooks.py:260] loss = 1.6349368, step = 22400 (46.345 sec)\n",
            "I0727 11:22:07.895227 139624873338752 basic_session_run_hooks.py:692] global_step/sec: 2.17393\n",
            "I0727 11:22:07.896099 139624873338752 basic_session_run_hooks.py:260] loss = 1.2555977, step = 22500 (45.999 sec)\n",
            "I0727 11:22:29.457964 139624873338752 basic_session_run_hooks.py:606] Saving checkpoints for 22548 into training/model.ckpt.\n",
            "I0727 11:22:31.366773 139624873338752 estimator.py:1145] Calling model_fn.\n",
            "I0727 11:22:33.223979 139624873338752 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "I0727 11:22:33.263099 139624873338752 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "I0727 11:22:33.302406 139624873338752 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "I0727 11:22:33.342742 139624873338752 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "I0727 11:22:33.381443 139624873338752 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "I0727 11:22:33.419811 139624873338752 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "I0727 11:22:35.459376 139624873338752 estimator.py:1147] Done calling model_fn.\n",
            "I0727 11:22:35.479695 139624873338752 evaluation.py:255] Starting evaluation at 2019-07-27T11:22:35Z\n",
            "I0727 11:22:35.820844 139624873338752 monitored_session.py:240] Graph was finalized.\n",
            "2019-07-27 11:22:35.821501: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-27 11:22:35.821884: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2019-07-27 11:22:35.821990: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
            "2019-07-27 11:22:35.822022: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
            "2019-07-27 11:22:35.822047: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\n",
            "2019-07-27 11:22:35.822082: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\n",
            "2019-07-27 11:22:35.822107: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2019-07-27 11:22:35.822130: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2019-07-27 11:22:35.822154: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
            "2019-07-27 11:22:35.822242: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-27 11:22:35.822591: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-27 11:22:35.822888: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
            "2019-07-27 11:22:35.822934: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-07-27 11:22:35.822949: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 \n",
            "2019-07-27 11:22:35.822960: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N \n",
            "2019-07-27 11:22:35.823215: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-27 11:22:35.823551: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-27 11:22:35.823862: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14202 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "I0727 11:22:35.825153 139624873338752 saver.py:1280] Restoring parameters from training/model.ckpt-22548\n",
            "I0727 11:22:36.472956 139624873338752 session_manager.py:500] Running local_init_op.\n",
            "I0727 11:22:36.562744 139624873338752 session_manager.py:502] Done running local_init_op.\n",
            "I0727 11:22:38.616750 139621908854528 coco_evaluation.py:205] Performing evaluation on 9 images.\n",
            "creating index...\n",
            "index created!\n",
            "I0727 11:22:38.617299 139621908854528 coco_tools.py:115] Loading and preparing annotation results...\n",
            "I0727 11:22:38.618058 139621908854528 coco_tools.py:137] DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.27s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.215\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.471\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.151\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.152\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.552\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.100\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.292\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.315\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.219\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.700\n",
            "I0727 11:22:39.598548 139624873338752 evaluation.py:275] Finished evaluation at 2019-07-27-11:22:39\n",
            "I0727 11:22:39.598865 139624873338752 estimator.py:2039] Saving dict for global step 22548: DetectionBoxes_Precision/mAP = 0.21503802, DetectionBoxes_Precision/mAP (large) = 0.55198514, DetectionBoxes_Precision/mAP (medium) = 0.15219116, DetectionBoxes_Precision/mAP (small) = 0.0, DetectionBoxes_Precision/mAP@.50IOU = 0.4706269, DetectionBoxes_Precision/mAP@.75IOU = 0.15065326, DetectionBoxes_Recall/AR@1 = 0.1, DetectionBoxes_Recall/AR@10 = 0.29166666, DetectionBoxes_Recall/AR@100 = 0.31458333, DetectionBoxes_Recall/AR@100 (large) = 0.7, DetectionBoxes_Recall/AR@100 (medium) = 0.21891892, DetectionBoxes_Recall/AR@100 (small) = 0.0, Loss/classification_loss = 9.417019, Loss/localization_loss = 1.260961, Loss/regularization_loss = 0.34363744, Loss/total_loss = 11.02162, global_step = 22548, learning_rate = 0.004, loss = 11.02162\n",
            "I0727 11:22:39.604203 139624873338752 estimator.py:2099] Saving 'checkpoint_path' summary for global step 22548: training/model.ckpt-22548\n",
            "I0727 11:23:04.111947 139624873338752 basic_session_run_hooks.py:692] global_step/sec: 1.77883\n",
            "I0727 11:23:04.112961 139624873338752 basic_session_run_hooks.py:260] loss = 0.94861996, step = 22600 (56.217 sec)\n",
            "I0727 11:23:50.678636 139624873338752 basic_session_run_hooks.py:692] global_step/sec: 2.14746\n",
            "I0727 11:23:50.679858 139624873338752 basic_session_run_hooks.py:260] loss = 1.0305157, step = 22700 (46.567 sec)\n",
            "I0727 11:24:36.503921 139624873338752 basic_session_run_hooks.py:692] global_step/sec: 2.1822\n",
            "I0727 11:24:36.505133 139624873338752 basic_session_run_hooks.py:260] loss = 1.214669, step = 22800 (45.825 sec)\n",
            "I0727 11:25:23.495580 139624873338752 basic_session_run_hooks.py:692] global_step/sec: 2.12804\n",
            "I0727 11:25:23.496905 139624873338752 basic_session_run_hooks.py:260] loss = 0.9127828, step = 22900 (46.992 sec)\n",
            "I0727 11:26:10.209453 139624873338752 basic_session_run_hooks.py:692] global_step/sec: 2.14068\n",
            "I0727 11:26:10.210685 139624873338752 basic_session_run_hooks.py:260] loss = 1.0994308, step = 23000 (46.714 sec)\n",
            "I0727 11:26:56.527525 139624873338752 basic_session_run_hooks.py:692] global_step/sec: 2.15899\n",
            "I0727 11:26:56.528667 139624873338752 basic_session_run_hooks.py:260] loss = 1.0412655, step = 23100 (46.318 sec)\n",
            "I0727 11:27:42.819643 139624873338752 basic_session_run_hooks.py:692] global_step/sec: 2.16019\n",
            "I0727 11:27:42.820702 139624873338752 basic_session_run_hooks.py:260] loss = 1.0211747, step = 23200 (46.292 sec)\n",
            "I0727 11:28:28.639029 139624873338752 basic_session_run_hooks.py:692] global_step/sec: 2.18248\n",
            "I0727 11:28:28.640326 139624873338752 basic_session_run_hooks.py:260] loss = 0.707811, step = 23300 (45.820 sec)\n",
            "I0727 11:29:14.992084 139624873338752 basic_session_run_hooks.py:692] global_step/sec: 2.15736\n",
            "I0727 11:29:14.993464 139624873338752 basic_session_run_hooks.py:260] loss = 1.1856875, step = 23400 (46.353 sec)\n",
            "I0727 11:30:01.144946 139624873338752 basic_session_run_hooks.py:692] global_step/sec: 2.16671\n",
            "I0727 11:30:01.146210 139624873338752 basic_session_run_hooks.py:260] loss = 1.0836377, step = 23500 (46.153 sec)\n",
            "I0727 11:30:47.270253 139624873338752 basic_session_run_hooks.py:692] global_step/sec: 2.16801\n",
            "I0727 11:30:47.271446 139624873338752 basic_session_run_hooks.py:260] loss = 1.7635963, step = 23600 (46.125 sec)\n",
            "I0727 11:31:33.863642 139624873338752 basic_session_run_hooks.py:692] global_step/sec: 2.14623\n",
            "I0727 11:31:33.864950 139624873338752 basic_session_run_hooks.py:260] loss = 1.2903929, step = 23700 (46.594 sec)\n",
            "I0727 11:32:20.104178 139624873338752 basic_session_run_hooks.py:692] global_step/sec: 2.1626\n",
            "I0727 11:32:20.105172 139624873338752 basic_session_run_hooks.py:260] loss = 0.943961, step = 23800 (46.240 sec)\n",
            "I0727 11:32:29.671357 139624873338752 basic_session_run_hooks.py:606] Saving checkpoints for 23822 into training/model.ckpt.\n",
            "I0727 11:32:31.644208 139624873338752 estimator.py:1145] Calling model_fn.\n",
            "I0727 11:32:33.956601 139624873338752 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "I0727 11:32:33.996003 139624873338752 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "I0727 11:32:34.033738 139624873338752 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "I0727 11:32:34.076143 139624873338752 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "I0727 11:32:34.116693 139624873338752 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "I0727 11:32:34.154864 139624873338752 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "I0727 11:32:35.717400 139624873338752 estimator.py:1147] Done calling model_fn.\n",
            "I0727 11:32:35.737470 139624873338752 evaluation.py:255] Starting evaluation at 2019-07-27T11:32:35Z\n",
            "I0727 11:32:36.071396 139624873338752 monitored_session.py:240] Graph was finalized.\n",
            "2019-07-27 11:32:36.072130: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-27 11:32:36.072508: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2019-07-27 11:32:36.072659: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
            "2019-07-27 11:32:36.072698: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
            "2019-07-27 11:32:36.072720: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\n",
            "2019-07-27 11:32:36.072742: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\n",
            "2019-07-27 11:32:36.072761: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2019-07-27 11:32:36.072781: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2019-07-27 11:32:36.072823: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
            "2019-07-27 11:32:36.072925: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-27 11:32:36.073270: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-27 11:32:36.073553: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
            "2019-07-27 11:32:36.073627: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-07-27 11:32:36.073643: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 \n",
            "2019-07-27 11:32:36.073658: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N \n",
            "2019-07-27 11:32:36.073950: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-27 11:32:36.074300: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-27 11:32:36.074623: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14202 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "I0727 11:32:36.076030 139624873338752 saver.py:1280] Restoring parameters from training/model.ckpt-23822\n",
            "I0727 11:32:36.744339 139624873338752 session_manager.py:500] Running local_init_op.\n",
            "I0727 11:32:36.839155 139624873338752 session_manager.py:502] Done running local_init_op.\n",
            "I0727 11:32:38.911319 139623159678720 coco_evaluation.py:205] Performing evaluation on 9 images.\n",
            "creating index...\n",
            "index created!\n",
            "I0727 11:32:38.911688 139623159678720 coco_tools.py:115] Loading and preparing annotation results...\n",
            "I0727 11:32:38.912342 139623159678720 coco_tools.py:137] DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.25s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.178\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.404\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.129\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.160\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.406\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.106\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.287\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.333\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.246\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.690\n",
            "I0727 11:32:39.890140 139624873338752 evaluation.py:275] Finished evaluation at 2019-07-27-11:32:39\n",
            "I0727 11:32:39.890424 139624873338752 estimator.py:2039] Saving dict for global step 23822: DetectionBoxes_Precision/mAP = 0.17764615, DetectionBoxes_Precision/mAP (large) = 0.40574366, DetectionBoxes_Precision/mAP (medium) = 0.16000558, DetectionBoxes_Precision/mAP (small) = 0.0, DetectionBoxes_Precision/mAP@.50IOU = 0.40385753, DetectionBoxes_Precision/mAP@.75IOU = 0.12853967, DetectionBoxes_Recall/AR@1 = 0.10625, DetectionBoxes_Recall/AR@10 = 0.2875, DetectionBoxes_Recall/AR@100 = 0.33333334, DetectionBoxes_Recall/AR@100 (large) = 0.69, DetectionBoxes_Recall/AR@100 (medium) = 0.24594595, DetectionBoxes_Recall/AR@100 (small) = 0.0, Loss/classification_loss = 13.033544, Loss/localization_loss = 1.3519379, Loss/regularization_loss = 0.34323, Loss/total_loss = 14.728712, global_step = 23822, learning_rate = 0.004, loss = 14.728712\n",
            "I0727 11:32:39.895362 139624873338752 estimator.py:2099] Saving 'checkpoint_path' summary for global step 23822: training/model.ckpt-23822\n",
            "I0727 11:33:16.731373 139624873338752 basic_session_run_hooks.py:692] global_step/sec: 1.76594\n",
            "I0727 11:33:16.732605 139624873338752 basic_session_run_hooks.py:260] loss = 1.4709582, step = 23900 (56.627 sec)\n",
            "I0727 11:34:02.812749 139624873338752 basic_session_run_hooks.py:692] global_step/sec: 2.17007\n",
            "I0727 11:34:02.813733 139624873338752 basic_session_run_hooks.py:260] loss = 1.4005544, step = 24000 (46.081 sec)\n",
            "I0727 11:34:49.219274 139624873338752 basic_session_run_hooks.py:692] global_step/sec: 2.15487\n",
            "I0727 11:34:49.220692 139624873338752 basic_session_run_hooks.py:260] loss = 1.9261402, step = 24100 (46.407 sec)\n",
            "I0727 11:35:35.496489 139624873338752 basic_session_run_hooks.py:692] global_step/sec: 2.16089\n",
            "I0727 11:35:35.497886 139624873338752 basic_session_run_hooks.py:260] loss = 1.92433, step = 24200 (46.277 sec)\n",
            "I0727 11:36:21.519390 139624873338752 basic_session_run_hooks.py:692] global_step/sec: 2.17283\n",
            "I0727 11:36:21.520550 139624873338752 basic_session_run_hooks.py:260] loss = 0.99906904, step = 24300 (46.023 sec)\n",
            "I0727 11:37:08.241361 139624873338752 basic_session_run_hooks.py:692] global_step/sec: 2.14032\n",
            "I0727 11:37:08.242618 139624873338752 basic_session_run_hooks.py:260] loss = 1.1822859, step = 24400 (46.722 sec)\n",
            "I0727 11:37:54.812355 139624873338752 basic_session_run_hooks.py:692] global_step/sec: 2.14726\n",
            "I0727 11:37:54.813485 139624873338752 basic_session_run_hooks.py:260] loss = 1.4050245, step = 24500 (46.571 sec)\n",
            "I0727 11:38:41.470065 139624873338752 basic_session_run_hooks.py:692] global_step/sec: 2.14327\n",
            "I0727 11:38:41.471128 139624873338752 basic_session_run_hooks.py:260] loss = 1.1892444, step = 24600 (46.658 sec)\n",
            "I0727 11:39:27.493509 139624873338752 basic_session_run_hooks.py:692] global_step/sec: 2.17281\n",
            "I0727 11:39:27.494866 139624873338752 basic_session_run_hooks.py:260] loss = 1.1065114, step = 24700 (46.024 sec)\n",
            "I0727 11:40:13.259161 139624873338752 basic_session_run_hooks.py:692] global_step/sec: 2.18504\n",
            "I0727 11:40:13.260263 139624873338752 basic_session_run_hooks.py:260] loss = 1.7548597, step = 24800 (45.765 sec)\n",
            "I0727 11:40:59.260271 139624873338752 basic_session_run_hooks.py:692] global_step/sec: 2.17386\n",
            "I0727 11:40:59.261329 139624873338752 basic_session_run_hooks.py:260] loss = 1.4264461, step = 24900 (46.001 sec)\n",
            "I0727 11:41:44.639692 139624873338752 basic_session_run_hooks.py:692] global_step/sec: 2.20364\n",
            "I0727 11:41:44.640721 139624873338752 basic_session_run_hooks.py:260] loss = 1.7629385, step = 25000 (45.379 sec)\n",
            "I0727 11:42:29.878295 139624873338752 basic_session_run_hooks.py:606] Saving checkpoints for 25099 into training/model.ckpt.\n",
            "I0727 11:42:31.854383 139624873338752 estimator.py:1145] Calling model_fn.\n",
            "I0727 11:42:34.153344 139624873338752 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "I0727 11:42:34.194342 139624873338752 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "I0727 11:42:34.233074 139624873338752 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "I0727 11:42:34.271289 139624873338752 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "I0727 11:42:34.315849 139624873338752 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "I0727 11:42:34.355782 139624873338752 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "I0727 11:42:35.898471 139624873338752 estimator.py:1147] Done calling model_fn.\n",
            "I0727 11:42:35.919760 139624873338752 evaluation.py:255] Starting evaluation at 2019-07-27T11:42:35Z\n",
            "I0727 11:42:36.246856 139624873338752 monitored_session.py:240] Graph was finalized.\n",
            "2019-07-27 11:42:36.247478: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-27 11:42:36.247861: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2019-07-27 11:42:36.247961: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
            "2019-07-27 11:42:36.247986: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
            "2019-07-27 11:42:36.248008: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\n",
            "2019-07-27 11:42:36.248028: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\n",
            "2019-07-27 11:42:36.248047: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2019-07-27 11:42:36.248072: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2019-07-27 11:42:36.248094: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
            "2019-07-27 11:42:36.248173: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-27 11:42:36.248517: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-27 11:42:36.248818: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
            "2019-07-27 11:42:36.248861: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-07-27 11:42:36.248874: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 \n",
            "2019-07-27 11:42:36.248883: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N \n",
            "2019-07-27 11:42:36.249112: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-27 11:42:36.249430: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-27 11:42:36.249741: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14202 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "I0727 11:42:36.250896 139624873338752 saver.py:1280] Restoring parameters from training/model.ckpt-25099\n",
            "I0727 11:42:36.901036 139624873338752 session_manager.py:500] Running local_init_op.\n",
            "I0727 11:42:36.996916 139624873338752 session_manager.py:502] Done running local_init_op.\n",
            "I0727 11:42:39.066758 139623159678720 coco_evaluation.py:205] Performing evaluation on 9 images.\n",
            "creating index...\n",
            "index created!\n",
            "I0727 11:42:39.067181 139623159678720 coco_tools.py:115] Loading and preparing annotation results...\n",
            "I0727 11:42:39.067997 139623159678720 coco_tools.py:137] DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.24s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.226\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.439\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.181\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.184\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.536\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.102\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.331\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.360\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.276\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.710\n",
            "I0727 11:42:40.046580 139624873338752 evaluation.py:275] Finished evaluation at 2019-07-27-11:42:40\n",
            "I0727 11:42:40.046890 139624873338752 estimator.py:2039] Saving dict for global step 25099: DetectionBoxes_Precision/mAP = 0.2260735, DetectionBoxes_Precision/mAP (large) = 0.53567153, DetectionBoxes_Precision/mAP (medium) = 0.1836786, DetectionBoxes_Precision/mAP (small) = 0.0, DetectionBoxes_Precision/mAP@.50IOU = 0.43886712, DetectionBoxes_Precision/mAP@.75IOU = 0.18143272, DetectionBoxes_Recall/AR@1 = 0.10208333, DetectionBoxes_Recall/AR@10 = 0.33125, DetectionBoxes_Recall/AR@100 = 0.36041668, DetectionBoxes_Recall/AR@100 (large) = 0.71, DetectionBoxes_Recall/AR@100 (medium) = 0.27567568, DetectionBoxes_Recall/AR@100 (small) = 0.0, Loss/classification_loss = 10.578624, Loss/localization_loss = 1.2760526, Loss/regularization_loss = 0.34282446, Loss/total_loss = 12.1975, global_step = 25099, learning_rate = 0.004, loss = 12.1975\n",
            "I0727 11:42:40.052505 139624873338752 estimator.py:2099] Saving 'checkpoint_path' summary for global step 25099: training/model.ckpt-25099\n",
            "I0727 11:42:41.160678 139624873338752 basic_session_run_hooks.py:692] global_step/sec: 1.76925\n",
            "I0727 11:42:41.161839 139624873338752 basic_session_run_hooks.py:260] loss = 1.2165135, step = 25100 (56.521 sec)\n",
            "I0727 11:43:27.274177 139624873338752 basic_session_run_hooks.py:692] global_step/sec: 2.16856\n",
            "I0727 11:43:27.275232 139624873338752 basic_session_run_hooks.py:260] loss = 2.2150116, step = 25200 (46.113 sec)\n",
            "I0727 11:44:13.564918 139624873338752 basic_session_run_hooks.py:692] global_step/sec: 2.16026\n",
            "I0727 11:44:13.566177 139624873338752 basic_session_run_hooks.py:260] loss = 1.3624142, step = 25300 (46.291 sec)\n",
            "I0727 11:44:59.390118 139624873338752 basic_session_run_hooks.py:692] global_step/sec: 2.18221\n",
            "I0727 11:44:59.391615 139624873338752 basic_session_run_hooks.py:260] loss = 1.4653175, step = 25400 (45.825 sec)\n",
            "I0727 11:45:45.331142 139624873338752 basic_session_run_hooks.py:692] global_step/sec: 2.1767\n",
            "I0727 11:45:45.332343 139624873338752 basic_session_run_hooks.py:260] loss = 1.2356607, step = 25500 (45.941 sec)\n",
            "I0727 11:46:31.534621 139624873338752 basic_session_run_hooks.py:692] global_step/sec: 2.16434\n",
            "I0727 11:46:31.536668 139624873338752 basic_session_run_hooks.py:260] loss = 1.4118329, step = 25600 (46.204 sec)\n",
            "I0727 11:47:18.030622 139624873338752 basic_session_run_hooks.py:692] global_step/sec: 2.15072\n",
            "I0727 11:47:18.031947 139624873338752 basic_session_run_hooks.py:260] loss = 1.380388, step = 25700 (46.495 sec)\n",
            "I0727 11:48:04.417241 139624873338752 basic_session_run_hooks.py:692] global_step/sec: 2.15579\n",
            "I0727 11:48:04.418394 139624873338752 basic_session_run_hooks.py:260] loss = 1.7649598, step = 25800 (46.386 sec)\n",
            "I0727 11:48:51.166428 139624873338752 basic_session_run_hooks.py:692] global_step/sec: 2.13907\n",
            "I0727 11:48:51.167661 139624873338752 basic_session_run_hooks.py:260] loss = 1.1636399, step = 25900 (46.749 sec)\n",
            "I0727 11:49:37.716563 139624873338752 basic_session_run_hooks.py:692] global_step/sec: 2.14822\n",
            "I0727 11:49:37.717772 139624873338752 basic_session_run_hooks.py:260] loss = 1.7221959, step = 26000 (46.550 sec)\n",
            "I0727 11:50:24.532222 139624873338752 basic_session_run_hooks.py:692] global_step/sec: 2.13604\n",
            "I0727 11:50:24.533472 139624873338752 basic_session_run_hooks.py:260] loss = 1.6150362, step = 26100 (46.816 sec)\n",
            "I0727 11:51:10.734915 139624873338752 basic_session_run_hooks.py:692] global_step/sec: 2.16438\n",
            "I0727 11:51:10.736090 139624873338752 basic_session_run_hooks.py:260] loss = 1.4623662, step = 26200 (46.203 sec)\n",
            "I0727 11:51:56.960676 139624873338752 basic_session_run_hooks.py:692] global_step/sec: 2.1633\n",
            "I0727 11:51:56.962011 139624873338752 basic_session_run_hooks.py:260] loss = 1.1997395, step = 26300 (46.226 sec)\n",
            "I0727 11:52:30.082716 139624873338752 basic_session_run_hooks.py:606] Saving checkpoints for 26373 into training/model.ckpt.\n",
            "I0727 11:52:32.537678 139624873338752 estimator.py:1145] Calling model_fn.\n",
            "I0727 11:52:34.452490 139624873338752 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "I0727 11:52:34.491599 139624873338752 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "I0727 11:52:34.529574 139624873338752 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "I0727 11:52:34.567824 139624873338752 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "I0727 11:52:34.605734 139624873338752 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "I0727 11:52:34.644686 139624873338752 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "I0727 11:52:36.516739 139624873338752 estimator.py:1147] Done calling model_fn.\n",
            "I0727 11:52:36.536895 139624873338752 evaluation.py:255] Starting evaluation at 2019-07-27T11:52:36Z\n",
            "I0727 11:52:36.865507 139624873338752 monitored_session.py:240] Graph was finalized.\n",
            "2019-07-27 11:52:36.866182: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-27 11:52:36.866547: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2019-07-27 11:52:36.866640: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
            "2019-07-27 11:52:36.866672: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
            "2019-07-27 11:52:36.866697: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\n",
            "2019-07-27 11:52:36.866724: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\n",
            "2019-07-27 11:52:36.866747: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2019-07-27 11:52:36.866768: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2019-07-27 11:52:36.866812: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
            "2019-07-27 11:52:36.866897: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-27 11:52:36.867248: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-27 11:52:36.867534: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
            "2019-07-27 11:52:36.867579: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-07-27 11:52:36.867594: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 \n",
            "2019-07-27 11:52:36.867605: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N \n",
            "2019-07-27 11:52:36.867840: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-27 11:52:36.868183: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-27 11:52:36.868482: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14202 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "I0727 11:52:36.869635 139624873338752 saver.py:1280] Restoring parameters from training/model.ckpt-26373\n",
            "I0727 11:52:37.525853 139624873338752 session_manager.py:500] Running local_init_op.\n",
            "I0727 11:52:37.619484 139624873338752 session_manager.py:502] Done running local_init_op.\n",
            "I0727 11:52:39.738589 139621908854528 coco_evaluation.py:205] Performing evaluation on 9 images.\n",
            "creating index...\n",
            "index created!\n",
            "I0727 11:52:39.738974 139621908854528 coco_tools.py:115] Loading and preparing annotation results...\n",
            "I0727 11:52:39.739710 139621908854528 coco_tools.py:137] DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.24s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.188\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.402\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.159\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.162\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.386\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.069\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.285\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.356\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.284\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.660\n",
            "I0727 11:52:40.687096 139624873338752 evaluation.py:275] Finished evaluation at 2019-07-27-11:52:40\n",
            "I0727 11:52:40.687366 139624873338752 estimator.py:2039] Saving dict for global step 26373: DetectionBoxes_Precision/mAP = 0.18828948, DetectionBoxes_Precision/mAP (large) = 0.3861307, DetectionBoxes_Precision/mAP (medium) = 0.16210492, DetectionBoxes_Precision/mAP (small) = 0.0, DetectionBoxes_Precision/mAP@.50IOU = 0.40217143, DetectionBoxes_Precision/mAP@.75IOU = 0.15901439, DetectionBoxes_Recall/AR@1 = 0.06875, DetectionBoxes_Recall/AR@10 = 0.28541666, DetectionBoxes_Recall/AR@100 = 0.35625, DetectionBoxes_Recall/AR@100 (large) = 0.66, DetectionBoxes_Recall/AR@100 (medium) = 0.2837838, DetectionBoxes_Recall/AR@100 (small) = 0.0, Loss/classification_loss = 11.206338, Loss/localization_loss = 1.4183239, Loss/regularization_loss = 0.3424242, Loss/total_loss = 12.967085, global_step = 26373, learning_rate = 0.004, loss = 12.967085\n",
            "I0727 11:52:40.692839 139624873338752 estimator.py:2099] Saving 'checkpoint_path' summary for global step 26373: training/model.ckpt-26373\n",
            "I0727 11:52:53.988922 139624873338752 basic_session_run_hooks.py:692] global_step/sec: 1.75351\n",
            "I0727 11:52:53.989904 139624873338752 basic_session_run_hooks.py:260] loss = 1.2651942, step = 26400 (57.028 sec)\n",
            "I0727 11:53:40.435951 139624873338752 basic_session_run_hooks.py:692] global_step/sec: 2.15299\n",
            "I0727 11:53:40.436947 139624873338752 basic_session_run_hooks.py:260] loss = 1.0499163, step = 26500 (46.447 sec)\n",
            "I0727 11:54:26.183053 139624873338752 basic_session_run_hooks.py:692] global_step/sec: 2.18593\n",
            "I0727 11:54:26.184309 139624873338752 basic_session_run_hooks.py:260] loss = 1.5505427, step = 26600 (45.747 sec)\n",
            "I0727 11:55:12.370847 139624873338752 basic_session_run_hooks.py:692] global_step/sec: 2.16507\n",
            "I0727 11:55:12.372023 139624873338752 basic_session_run_hooks.py:260] loss = 1.2494829, step = 26700 (46.188 sec)\n",
            "I0727 11:55:58.019478 139624873338752 basic_session_run_hooks.py:692] global_step/sec: 2.19065\n",
            "I0727 11:55:58.020583 139624873338752 basic_session_run_hooks.py:260] loss = 1.451663, step = 26800 (45.649 sec)\n",
            "I0727 11:56:43.731737 139624873338752 basic_session_run_hooks.py:692] global_step/sec: 2.18759\n",
            "I0727 11:56:43.732979 139624873338752 basic_session_run_hooks.py:260] loss = 1.2675419, step = 26900 (45.712 sec)\n",
            "I0727 11:57:30.026594 139624873338752 basic_session_run_hooks.py:692] global_step/sec: 2.16007\n",
            "I0727 11:57:30.027875 139624873338752 basic_session_run_hooks.py:260] loss = 1.0910321, step = 27000 (46.295 sec)\n",
            "I0727 11:58:16.211902 139624873338752 basic_session_run_hooks.py:692] global_step/sec: 2.16519\n",
            "I0727 11:58:16.212852 139624873338752 basic_session_run_hooks.py:260] loss = 1.7511561, step = 27100 (46.185 sec)\n",
            "I0727 11:59:01.786107 139624873338752 basic_session_run_hooks.py:692] global_step/sec: 2.19423\n",
            "I0727 11:59:01.787573 139624873338752 basic_session_run_hooks.py:260] loss = 1.4100548, step = 27200 (45.575 sec)\n",
            "I0727 11:59:48.064641 139624873338752 basic_session_run_hooks.py:692] global_step/sec: 2.16083\n",
            "I0727 11:59:48.065733 139624873338752 basic_session_run_hooks.py:260] loss = 1.4135423, step = 27300 (46.278 sec)\n",
            "I0727 12:00:33.893615 139624873338752 basic_session_run_hooks.py:692] global_step/sec: 2.18203\n",
            "I0727 12:00:33.894821 139624873338752 basic_session_run_hooks.py:260] loss = 1.4410918, step = 27400 (45.829 sec)\n",
            "I0727 12:01:19.881681 139624873338752 basic_session_run_hooks.py:692] global_step/sec: 2.17448\n",
            "I0727 12:01:19.883588 139624873338752 basic_session_run_hooks.py:260] loss = 1.0608423, step = 27500 (45.989 sec)\n",
            "I0727 12:02:05.573429 139624873338752 basic_session_run_hooks.py:692] global_step/sec: 2.18858\n",
            "I0727 12:02:05.574460 139624873338752 basic_session_run_hooks.py:260] loss = 0.95100254, step = 27600 (45.691 sec)\n",
            "I0727 12:02:30.447510 139624873338752 basic_session_run_hooks.py:606] Saving checkpoints for 27655 into training/model.ckpt.\n",
            "I0727 12:02:32.441803 139624873338752 estimator.py:1145] Calling model_fn.\n",
            "I0727 12:02:34.303566 139624873338752 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "I0727 12:02:34.343397 139624873338752 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "I0727 12:02:34.382627 139624873338752 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "I0727 12:02:34.421365 139624873338752 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "I0727 12:02:34.466539 139624873338752 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "I0727 12:02:34.506364 139624873338752 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "I0727 12:02:36.574561 139624873338752 estimator.py:1147] Done calling model_fn.\n",
            "I0727 12:02:36.596229 139624873338752 evaluation.py:255] Starting evaluation at 2019-07-27T12:02:36Z\n",
            "I0727 12:02:36.939215 139624873338752 monitored_session.py:240] Graph was finalized.\n",
            "2019-07-27 12:02:36.939947: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-27 12:02:36.940330: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2019-07-27 12:02:36.940431: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
            "2019-07-27 12:02:36.940461: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
            "2019-07-27 12:02:36.940482: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\n",
            "2019-07-27 12:02:36.940512: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\n",
            "2019-07-27 12:02:36.940543: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2019-07-27 12:02:36.940562: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2019-07-27 12:02:36.940594: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
            "2019-07-27 12:02:36.940697: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-27 12:02:36.941113: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-27 12:02:36.941408: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
            "2019-07-27 12:02:36.941455: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-07-27 12:02:36.941480: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 \n",
            "2019-07-27 12:02:36.941492: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N \n",
            "2019-07-27 12:02:36.941724: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-27 12:02:36.942089: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-27 12:02:36.942395: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14202 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "I0727 12:02:36.943597 139624873338752 saver.py:1280] Restoring parameters from training/model.ckpt-27655\n",
            "I0727 12:02:37.625713 139624873338752 session_manager.py:500] Running local_init_op.\n",
            "I0727 12:02:37.730800 139624873338752 session_manager.py:502] Done running local_init_op.\n",
            "I0727 12:02:39.892242 139621908854528 coco_evaluation.py:205] Performing evaluation on 9 images.\n",
            "creating index...\n",
            "index created!\n",
            "I0727 12:02:39.892647 139621908854528 coco_tools.py:115] Loading and preparing annotation results...\n",
            "I0727 12:02:39.893402 139621908854528 coco_tools.py:137] DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.24s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.183\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.350\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.156\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.140\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.476\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.098\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.258\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.340\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.259\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.670\n",
            "I0727 12:02:40.879251 139624873338752 evaluation.py:275] Finished evaluation at 2019-07-27-12:02:40\n",
            "I0727 12:02:40.879533 139624873338752 estimator.py:2039] Saving dict for global step 27655: DetectionBoxes_Precision/mAP = 0.18296722, DetectionBoxes_Precision/mAP (large) = 0.4760958, DetectionBoxes_Precision/mAP (medium) = 0.13951287, DetectionBoxes_Precision/mAP (small) = 0.0, DetectionBoxes_Precision/mAP@.50IOU = 0.35002598, DetectionBoxes_Precision/mAP@.75IOU = 0.15624589, DetectionBoxes_Recall/AR@1 = 0.09791667, DetectionBoxes_Recall/AR@10 = 0.25833333, DetectionBoxes_Recall/AR@100 = 0.33958334, DetectionBoxes_Recall/AR@100 (large) = 0.67, DetectionBoxes_Recall/AR@100 (medium) = 0.25945947, DetectionBoxes_Recall/AR@100 (small) = 0.0, Loss/classification_loss = 12.141209, Loss/localization_loss = 1.4597132, Loss/regularization_loss = 0.34202406, Loss/total_loss = 13.942944, global_step = 27655, learning_rate = 0.004, loss = 13.942944\n",
            "I0727 12:02:40.886628 139624873338752 estimator.py:2099] Saving 'checkpoint_path' summary for global step 27655: training/model.ckpt-27655\n",
            "I0727 12:03:02.181065 139624873338752 basic_session_run_hooks.py:692] global_step/sec: 1.76655\n",
            "I0727 12:03:02.182306 139624873338752 basic_session_run_hooks.py:260] loss = 1.075652, step = 27700 (56.608 sec)\n",
            "I0727 12:03:47.667908 139624873338752 basic_session_run_hooks.py:692] global_step/sec: 2.19843\n",
            "I0727 12:03:47.669201 139624873338752 basic_session_run_hooks.py:260] loss = 1.1710176, step = 27800 (45.487 sec)\n",
            "I0727 12:04:33.494693 139624873338752 basic_session_run_hooks.py:692] global_step/sec: 2.18213\n",
            "I0727 12:04:33.495909 139624873338752 basic_session_run_hooks.py:260] loss = 1.2232826, step = 27900 (45.827 sec)\n",
            "I0727 12:05:19.814773 139624873338752 basic_session_run_hooks.py:692] global_step/sec: 2.15889\n",
            "I0727 12:05:19.815926 139624873338752 basic_session_run_hooks.py:260] loss = 1.3898721, step = 28000 (46.320 sec)\n",
            "I0727 12:06:07.297812 139624873338752 basic_session_run_hooks.py:692] global_step/sec: 2.10602\n",
            "I0727 12:06:07.298853 139624873338752 basic_session_run_hooks.py:260] loss = 1.6300538, step = 28100 (47.483 sec)\n",
            "I0727 12:06:53.642156 139624873338752 basic_session_run_hooks.py:692] global_step/sec: 2.15776\n",
            "I0727 12:06:53.643171 139624873338752 basic_session_run_hooks.py:260] loss = 0.844889, step = 28200 (46.344 sec)\n",
            "I0727 12:07:39.993969 139624873338752 basic_session_run_hooks.py:692] global_step/sec: 2.15741\n",
            "I0727 12:07:39.994998 139624873338752 basic_session_run_hooks.py:260] loss = 1.0320218, step = 28300 (46.352 sec)\n",
            "I0727 12:08:26.401745 139624873338752 basic_session_run_hooks.py:692] global_step/sec: 2.15481\n",
            "I0727 12:08:26.402882 139624873338752 basic_session_run_hooks.py:260] loss = 1.1388011, step = 28400 (46.408 sec)\n",
            "I0727 12:09:12.911823 139624873338752 basic_session_run_hooks.py:692] global_step/sec: 2.15007\n",
            "I0727 12:09:12.913103 139624873338752 basic_session_run_hooks.py:260] loss = 1.2074226, step = 28500 (46.510 sec)\n",
            "I0727 12:09:58.845526 139624873338752 basic_session_run_hooks.py:692] global_step/sec: 2.17705\n",
            "I0727 12:09:58.846590 139624873338752 basic_session_run_hooks.py:260] loss = 1.0049703, step = 28600 (45.933 sec)\n",
            "I0727 12:10:45.440932 139624873338752 basic_session_run_hooks.py:692] global_step/sec: 2.14615\n",
            "I0727 12:10:45.442302 139624873338752 basic_session_run_hooks.py:260] loss = 0.99880904, step = 28700 (46.596 sec)\n",
            "I0727 12:11:32.192470 139624873338752 basic_session_run_hooks.py:692] global_step/sec: 2.13896\n",
            "I0727 12:11:32.193681 139624873338752 basic_session_run_hooks.py:260] loss = 1.6240618, step = 28800 (46.751 sec)\n",
            "I0727 12:12:18.523638 139624873338752 basic_session_run_hooks.py:692] global_step/sec: 2.15837\n",
            "I0727 12:12:18.525085 139624873338752 basic_session_run_hooks.py:260] loss = 1.1718752, step = 28900 (46.331 sec)\n",
            "I0727 12:12:30.628511 139624873338752 basic_session_run_hooks.py:606] Saving checkpoints for 28927 into training/model.ckpt.\n",
            "I0727 12:12:32.657699 139624873338752 estimator.py:1145] Calling model_fn.\n",
            "I0727 12:12:35.003428 139624873338752 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "I0727 12:12:35.043781 139624873338752 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "I0727 12:12:35.083488 139624873338752 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "I0727 12:12:35.122305 139624873338752 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "I0727 12:12:35.161512 139624873338752 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "I0727 12:12:35.208570 139624873338752 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "I0727 12:12:36.803898 139624873338752 estimator.py:1147] Done calling model_fn.\n",
            "I0727 12:12:36.824031 139624873338752 evaluation.py:255] Starting evaluation at 2019-07-27T12:12:36Z\n",
            "I0727 12:12:37.157545 139624873338752 monitored_session.py:240] Graph was finalized.\n",
            "2019-07-27 12:12:37.158217: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-27 12:12:37.158590: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2019-07-27 12:12:37.158680: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
            "2019-07-27 12:12:37.158712: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
            "2019-07-27 12:12:37.158737: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\n",
            "2019-07-27 12:12:37.158766: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\n",
            "2019-07-27 12:12:37.158808: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2019-07-27 12:12:37.158831: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2019-07-27 12:12:37.158854: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
            "2019-07-27 12:12:37.158942: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-27 12:12:37.159321: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-27 12:12:37.159605: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
            "2019-07-27 12:12:37.159651: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-07-27 12:12:37.159666: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 \n",
            "2019-07-27 12:12:37.159677: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N \n",
            "2019-07-27 12:12:37.159924: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-27 12:12:37.160252: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-27 12:12:37.160573: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14202 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "I0727 12:12:37.161734 139624873338752 saver.py:1280] Restoring parameters from training/model.ckpt-28927\n",
            "I0727 12:12:37.840828 139624873338752 session_manager.py:500] Running local_init_op.\n",
            "I0727 12:12:37.936869 139624873338752 session_manager.py:502] Done running local_init_op.\n",
            "I0727 12:12:40.031335 139621908854528 coco_evaluation.py:205] Performing evaluation on 9 images.\n",
            "creating index...\n",
            "index created!\n",
            "I0727 12:12:40.032673 139621908854528 coco_tools.py:115] Loading and preparing annotation results...\n",
            "I0727 12:12:40.033868 139621908854528 coco_tools.py:137] DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.24s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.169\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.354\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.101\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.123\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.437\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.100\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.248\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.302\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.222\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.630\n",
            "I0727 12:12:40.991985 139624873338752 evaluation.py:275] Finished evaluation at 2019-07-27-12:12:40\n",
            "I0727 12:12:40.992280 139624873338752 estimator.py:2039] Saving dict for global step 28927: DetectionBoxes_Precision/mAP = 0.16930309, DetectionBoxes_Precision/mAP (large) = 0.43702847, DetectionBoxes_Precision/mAP (medium) = 0.12326195, DetectionBoxes_Precision/mAP (small) = 0.0, DetectionBoxes_Precision/mAP@.50IOU = 0.3542236, DetectionBoxes_Precision/mAP@.75IOU = 0.100872494, DetectionBoxes_Recall/AR@1 = 0.1, DetectionBoxes_Recall/AR@10 = 0.24791667, DetectionBoxes_Recall/AR@100 = 0.30208334, DetectionBoxes_Recall/AR@100 (large) = 0.63, DetectionBoxes_Recall/AR@100 (medium) = 0.22162162, DetectionBoxes_Recall/AR@100 (small) = 0.0, Loss/classification_loss = 12.978655, Loss/localization_loss = 1.4826903, Loss/regularization_loss = 0.3415828, Loss/total_loss = 14.802929, global_step = 28927, learning_rate = 0.004, loss = 14.802929\n",
            "I0727 12:12:40.997757 139624873338752 estimator.py:2099] Saving 'checkpoint_path' summary for global step 28927: training/model.ckpt-28927\n",
            "I0727 12:13:15.777026 139624873338752 basic_session_run_hooks.py:692] global_step/sec: 1.74662\n",
            "I0727 12:13:15.778549 139624873338752 basic_session_run_hooks.py:260] loss = 1.885042, step = 29000 (57.253 sec)\n",
            "I0727 12:14:01.835423 139624873338752 basic_session_run_hooks.py:692] global_step/sec: 2.17116\n",
            "I0727 12:14:01.836536 139624873338752 basic_session_run_hooks.py:260] loss = 1.2268414, step = 29100 (46.058 sec)\n",
            "I0727 12:14:47.878078 139624873338752 basic_session_run_hooks.py:692] global_step/sec: 2.1719\n",
            "I0727 12:14:47.879229 139624873338752 basic_session_run_hooks.py:260] loss = 1.7609117, step = 29200 (46.043 sec)\n",
            "I0727 12:15:33.409908 139624873338752 basic_session_run_hooks.py:692] global_step/sec: 2.19627\n",
            "I0727 12:15:33.411259 139624873338752 basic_session_run_hooks.py:260] loss = 1.2781888, step = 29300 (45.532 sec)\n",
            "I0727 12:16:19.889203 139624873338752 basic_session_run_hooks.py:692] global_step/sec: 2.15149\n",
            "I0727 12:16:19.890311 139624873338752 basic_session_run_hooks.py:260] loss = 1.2877414, step = 29400 (46.479 sec)\n",
            "I0727 12:17:06.101608 139624873338752 basic_session_run_hooks.py:692] global_step/sec: 2.16392\n",
            "I0727 12:17:06.102893 139624873338752 basic_session_run_hooks.py:260] loss = 1.3734493, step = 29500 (46.213 sec)\n",
            "I0727 12:17:51.825439 139624873338752 basic_session_run_hooks.py:692] global_step/sec: 2.18704\n",
            "I0727 12:17:51.827228 139624873338752 basic_session_run_hooks.py:260] loss = 0.92592126, step = 29600 (45.724 sec)\n",
            "I0727 12:18:38.074351 139624873338752 basic_session_run_hooks.py:692] global_step/sec: 2.16221\n",
            "I0727 12:18:38.075567 139624873338752 basic_session_run_hooks.py:260] loss = 1.7318064, step = 29700 (46.248 sec)\n",
            "I0727 12:19:24.552186 139624873338752 basic_session_run_hooks.py:692] global_step/sec: 2.15156\n",
            "I0727 12:19:24.553547 139624873338752 basic_session_run_hooks.py:260] loss = 1.1232527, step = 29800 (46.478 sec)\n",
            "I0727 12:20:10.994069 139624873338752 basic_session_run_hooks.py:692] global_step/sec: 2.15323\n",
            "I0727 12:20:10.995288 139624873338752 basic_session_run_hooks.py:260] loss = 1.794401, step = 29900 (46.442 sec)\n",
            "I0727 12:20:56.685730 139624873338752 basic_session_run_hooks.py:606] Saving checkpoints for 30000 into training/model.ckpt.\n",
            "I0727 12:20:57.971690 139624873338752 training.py:527] Skip the current checkpoint eval due to throttle secs (600 secs).\n",
            "I0727 12:20:58.765384 139624873338752 estimator.py:1145] Calling model_fn.\n",
            "I0727 12:21:01.094274 139624873338752 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "I0727 12:21:01.133065 139624873338752 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "I0727 12:21:01.171420 139624873338752 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "I0727 12:21:01.211188 139624873338752 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "I0727 12:21:01.249082 139624873338752 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "I0727 12:21:01.287922 139624873338752 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "I0727 12:21:02.836002 139624873338752 estimator.py:1147] Done calling model_fn.\n",
            "I0727 12:21:02.857491 139624873338752 evaluation.py:255] Starting evaluation at 2019-07-27T12:21:02Z\n",
            "I0727 12:21:03.539067 139624873338752 monitored_session.py:240] Graph was finalized.\n",
            "2019-07-27 12:21:03.539751: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-27 12:21:03.540163: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2019-07-27 12:21:03.540286: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
            "2019-07-27 12:21:03.540320: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
            "2019-07-27 12:21:03.540341: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\n",
            "2019-07-27 12:21:03.540363: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\n",
            "2019-07-27 12:21:03.540381: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2019-07-27 12:21:03.540399: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2019-07-27 12:21:03.540418: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
            "2019-07-27 12:21:03.540515: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-27 12:21:03.541070: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-27 12:21:03.541498: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
            "2019-07-27 12:21:03.541563: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-07-27 12:21:03.541585: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 \n",
            "2019-07-27 12:21:03.541600: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N \n",
            "2019-07-27 12:21:03.541866: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-27 12:21:03.542200: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-27 12:21:03.542515: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14202 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "I0727 12:21:03.543761 139624873338752 saver.py:1280] Restoring parameters from training/model.ckpt-30000\n",
            "I0727 12:21:04.213895 139624873338752 session_manager.py:500] Running local_init_op.\n",
            "I0727 12:21:04.313709 139624873338752 session_manager.py:502] Done running local_init_op.\n",
            "I0727 12:21:06.413120 139621908854528 coco_evaluation.py:205] Performing evaluation on 9 images.\n",
            "creating index...\n",
            "index created!\n",
            "I0727 12:21:06.413620 139621908854528 coco_tools.py:115] Loading and preparing annotation results...\n",
            "I0727 12:21:06.415587 139621908854528 coco_tools.py:137] DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.27s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.167\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.363\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.092\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.099\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.470\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.090\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.219\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.285\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.195\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.650\n",
            "I0727 12:21:07.395105 139624873338752 evaluation.py:275] Finished evaluation at 2019-07-27-12:21:07\n",
            "I0727 12:21:07.395415 139624873338752 estimator.py:2039] Saving dict for global step 30000: DetectionBoxes_Precision/mAP = 0.16709505, DetectionBoxes_Precision/mAP (large) = 0.47027168, DetectionBoxes_Precision/mAP (medium) = 0.09852802, DetectionBoxes_Precision/mAP (small) = 0.0, DetectionBoxes_Precision/mAP@.50IOU = 0.3625949, DetectionBoxes_Precision/mAP@.75IOU = 0.09150285, DetectionBoxes_Recall/AR@1 = 0.08958333, DetectionBoxes_Recall/AR@10 = 0.21875, DetectionBoxes_Recall/AR@100 = 0.28541666, DetectionBoxes_Recall/AR@100 (large) = 0.65, DetectionBoxes_Recall/AR@100 (medium) = 0.19459459, DetectionBoxes_Recall/AR@100 (small) = 0.0, Loss/classification_loss = 10.883148, Loss/localization_loss = 1.505751, Loss/regularization_loss = 0.34120703, Loss/total_loss = 12.730106, global_step = 30000, learning_rate = 0.004, loss = 12.730106\n",
            "I0727 12:21:07.400508 139624873338752 estimator.py:2099] Saving 'checkpoint_path' summary for global step 30000: training/model.ckpt-30000\n",
            "I0727 12:21:07.401258 139624873338752 exporter.py:410] Performing the final export in the end of training.\n",
            "I0727 12:21:07.632285 139624873338752 estimator.py:1145] Calling model_fn.\n",
            "I0727 12:21:09.501323 139624873338752 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "I0727 12:21:09.540338 139624873338752 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "I0727 12:21:09.578892 139624873338752 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "I0727 12:21:09.617114 139624873338752 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "I0727 12:21:09.655176 139624873338752 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "I0727 12:21:09.701924 139624873338752 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "W0727 12:21:10.164854 139624873338752 deprecation_wrapper.py:119] From /content/models/research/object_detection/model_lib.py:418: The name tf.saved_model.signature_constants.PREDICT_METHOD_NAME is deprecated. Please use tf.saved_model.PREDICT_METHOD_NAME instead.\n",
            "\n",
            "I0727 12:21:10.347509 139624873338752 estimator.py:1147] Done calling model_fn.\n",
            "W0727 12:21:10.347779 139624873338752 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/signature_def_utils_impl.py:201: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
            "I0727 12:21:10.348442 139624873338752 export_utils.py:170] Signatures INCLUDED in export for Classify: None\n",
            "I0727 12:21:10.348541 139624873338752 export_utils.py:170] Signatures INCLUDED in export for Regress: None\n",
            "I0727 12:21:10.348613 139624873338752 export_utils.py:170] Signatures INCLUDED in export for Predict: ['tensorflow/serving/predict', 'serving_default']\n",
            "I0727 12:21:10.348672 139624873338752 export_utils.py:170] Signatures INCLUDED in export for Train: None\n",
            "I0727 12:21:10.348736 139624873338752 export_utils.py:170] Signatures INCLUDED in export for Eval: None\n",
            "2019-07-27 12:21:10.349257: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-27 12:21:10.349634: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2019-07-27 12:21:10.349728: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
            "2019-07-27 12:21:10.349754: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
            "2019-07-27 12:21:10.349777: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\n",
            "2019-07-27 12:21:10.349816: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\n",
            "2019-07-27 12:21:10.349838: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2019-07-27 12:21:10.349858: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2019-07-27 12:21:10.349880: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
            "2019-07-27 12:21:10.349960: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-27 12:21:10.350288: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-27 12:21:10.350557: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
            "2019-07-27 12:21:10.350597: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-07-27 12:21:10.350611: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 \n",
            "2019-07-27 12:21:10.350621: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N \n",
            "2019-07-27 12:21:10.350851: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-27 12:21:10.351174: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-27 12:21:10.351456: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14202 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "I0727 12:21:10.354217 139624873338752 saver.py:1280] Restoring parameters from training/model.ckpt-30000\n",
            "I0727 12:21:10.670189 139624873338752 builder_impl.py:661] Assets added to graph.\n",
            "I0727 12:21:10.670381 139624873338752 builder_impl.py:456] No assets to write.\n",
            "I0727 12:21:11.251284 139624873338752 builder_impl.py:421] SavedModel written to: training/export/Servo/temp-b'1564230067'/saved_model.pb\n",
            "I0727 12:21:11.536404 139624873338752 estimator.py:368] Loss for final step: 1.0723429.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hsRMTSjRY6OJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c8cc1348-2ad4-4b7c-854e-db51f6ec9501"
      },
      "source": [
        "import re\n",
        "import numpy as np\n",
        "\n",
        "output_directory = './fine_tuned_model'\n",
        "\n",
        "lst = os.listdir(model_dir)\n",
        "lst = [l for l in lst if 'model.ckpt-' in l and '.meta' in l]\n",
        "steps=np.array([int(re.findall('\\d+', l)[0]) for l in lst])\n",
        "last_model = lst[steps.argmax()].replace('.meta', '')\n",
        "\n",
        "last_model_path = os.path.join(model_dir, last_model)\n",
        "print(last_model_path)\n",
        "!python /content/models/research/object_detection/export_inference_graph.py \\\n",
        "    --input_type=image_tensor \\\n",
        "    --pipeline_config_path={pipeline_fname} \\\n",
        "    --output_directory={output_directory} \\\n",
        "    --trained_checkpoint_prefix={last_model_path}"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training/model.ckpt-30000\n",
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0727 12:24:40.332121 140429546862464 deprecation_wrapper.py:119] From /content/models/research/slim/nets/inception_resnet_v2.py:373: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
            "\n",
            "W0727 12:24:40.343328 140429546862464 deprecation_wrapper.py:119] From /content/models/research/slim/nets/mobilenet/mobilenet.py:397: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
            "\n",
            "W0727 12:24:40.354512 140429546862464 deprecation_wrapper.py:119] From /content/models/research/object_detection/export_inference_graph.py:162: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
            "\n",
            "W0727 12:24:40.355143 140429546862464 deprecation_wrapper.py:119] From /content/models/research/object_detection/export_inference_graph.py:145: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "W0727 12:24:40.361516 140429546862464 deprecation_wrapper.py:119] From /content/models/research/object_detection/exporter.py:381: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
            "\n",
            "W0727 12:24:40.361834 140429546862464 deprecation_wrapper.py:119] From /content/models/research/object_detection/exporter.py:113: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0727 12:24:40.400770 140429546862464 deprecation_wrapper.py:119] From /content/models/research/object_detection/core/preprocessor.py:2660: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\n",
            "\n",
            "W0727 12:24:40.433932 140429546862464 deprecation_wrapper.py:119] From /content/models/research/object_detection/meta_architectures/ssd_meta_arch.py:575: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "W0727 12:24:42.595994 140429546862464 deprecation_wrapper.py:119] From /content/models/research/object_detection/core/anchor_generator.py:154: The name tf.assert_equal is deprecated. Please use tf.compat.v1.assert_equal instead.\n",
            "\n",
            "W0727 12:24:42.610276 140429546862464 deprecation_wrapper.py:119] From /content/models/research/object_detection/predictors/convolutional_box_predictor.py:150: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n",
            "I0727 12:24:42.610441 140429546862464 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "I0727 12:24:42.658756 140429546862464 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "I0727 12:24:42.705744 140429546862464 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "I0727 12:24:42.753886 140429546862464 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "I0727 12:24:42.802022 140429546862464 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "I0727 12:24:42.853642 140429546862464 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "W0727 12:24:43.289231 140429546862464 deprecation.py:323] From /content/models/research/object_detection/core/post_processing.py:567: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0727 12:24:43.649587 140429546862464 deprecation_wrapper.py:119] From /content/models/research/object_detection/exporter.py:260: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n",
            "\n",
            "W0727 12:24:43.649871 140429546862464 deprecation.py:323] From /content/models/research/object_detection/exporter.py:362: get_or_create_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please switch to tf.train.get_or_create_global_step\n",
            "W0727 12:24:43.653866 140429546862464 deprecation.py:323] From /content/models/research/object_detection/exporter.py:518: print_model_analysis (from tensorflow.contrib.tfprof.model_analyzer) is deprecated and will be removed after 2018-01-01.\n",
            "Instructions for updating:\n",
            "Use `tf.profiler.profile(graph, run_meta, op_log, cmd, options)`. Build `options` with `tf.profiler.ProfileOptionBuilder`. See README.md for details\n",
            "W0727 12:24:43.655009 140429546862464 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/profiler/internal/flops_registry.py:142: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n",
            "111 ops no flops stats due to incomplete shapes.\n",
            "Parsing Inputs...\n",
            "Incomplete shape.\n",
            "\n",
            "=========================Options=============================\n",
            "-max_depth                  10000\n",
            "-min_bytes                  0\n",
            "-min_peak_bytes             0\n",
            "-min_residual_bytes         0\n",
            "-min_output_bytes           0\n",
            "-min_micros                 0\n",
            "-min_accelerator_micros     0\n",
            "-min_cpu_micros             0\n",
            "-min_params                 0\n",
            "-min_float_ops              0\n",
            "-min_occurrence             0\n",
            "-step                       -1\n",
            "-order_by                   name\n",
            "-account_type_regexes       _trainable_variables\n",
            "-start_name_regexes         .*\n",
            "-trim_name_regexes          .*BatchNorm.*\n",
            "-show_name_regexes          .*\n",
            "-hide_name_regexes          \n",
            "-account_displayed_op_only  true\n",
            "-select                     params\n",
            "-output                     stdout:\n",
            "\n",
            "==================Model Analysis Report======================\n",
            "Incomplete shape.\n",
            "\n",
            "Doc:\n",
            "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
            "param: Number of parameters (in the Variable).\n",
            "\n",
            "Profile:\n",
            "node name | # parameters\n",
            "_TFProfRoot (--/5.49m params)\n",
            "  BoxPredictor_0 (--/9.23k params)\n",
            "    BoxPredictor_0/BoxEncodingPredictor (--/6.16k params)\n",
            "      BoxPredictor_0/BoxEncodingPredictor/biases (12, 12/12 params)\n",
            "      BoxPredictor_0/BoxEncodingPredictor/weights (1x1x512x12, 6.14k/6.14k params)\n",
            "    BoxPredictor_0/ClassPredictor (--/3.08k params)\n",
            "      BoxPredictor_0/ClassPredictor/biases (6, 6/6 params)\n",
            "      BoxPredictor_0/ClassPredictor/weights (1x1x512x6, 3.07k/3.07k params)\n",
            "  BoxPredictor_1 (--/36.90k params)\n",
            "    BoxPredictor_1/BoxEncodingPredictor (--/24.60k params)\n",
            "      BoxPredictor_1/BoxEncodingPredictor/biases (24, 24/24 params)\n",
            "      BoxPredictor_1/BoxEncodingPredictor/weights (1x1x1024x24, 24.58k/24.58k params)\n",
            "    BoxPredictor_1/ClassPredictor (--/12.30k params)\n",
            "      BoxPredictor_1/ClassPredictor/biases (12, 12/12 params)\n",
            "      BoxPredictor_1/ClassPredictor/weights (1x1x1024x12, 12.29k/12.29k params)\n",
            "  BoxPredictor_2 (--/18.47k params)\n",
            "    BoxPredictor_2/BoxEncodingPredictor (--/12.31k params)\n",
            "      BoxPredictor_2/BoxEncodingPredictor/biases (24, 24/24 params)\n",
            "      BoxPredictor_2/BoxEncodingPredictor/weights (1x1x512x24, 12.29k/12.29k params)\n",
            "    BoxPredictor_2/ClassPredictor (--/6.16k params)\n",
            "      BoxPredictor_2/ClassPredictor/biases (12, 12/12 params)\n",
            "      BoxPredictor_2/ClassPredictor/weights (1x1x512x12, 6.14k/6.14k params)\n",
            "  BoxPredictor_3 (--/9.25k params)\n",
            "    BoxPredictor_3/BoxEncodingPredictor (--/6.17k params)\n",
            "      BoxPredictor_3/BoxEncodingPredictor/biases (24, 24/24 params)\n",
            "      BoxPredictor_3/BoxEncodingPredictor/weights (1x1x256x24, 6.14k/6.14k params)\n",
            "    BoxPredictor_3/ClassPredictor (--/3.08k params)\n",
            "      BoxPredictor_3/ClassPredictor/biases (12, 12/12 params)\n",
            "      BoxPredictor_3/ClassPredictor/weights (1x1x256x12, 3.07k/3.07k params)\n",
            "  BoxPredictor_4 (--/9.25k params)\n",
            "    BoxPredictor_4/BoxEncodingPredictor (--/6.17k params)\n",
            "      BoxPredictor_4/BoxEncodingPredictor/biases (24, 24/24 params)\n",
            "      BoxPredictor_4/BoxEncodingPredictor/weights (1x1x256x24, 6.14k/6.14k params)\n",
            "    BoxPredictor_4/ClassPredictor (--/3.08k params)\n",
            "      BoxPredictor_4/ClassPredictor/biases (12, 12/12 params)\n",
            "      BoxPredictor_4/ClassPredictor/weights (1x1x256x12, 3.07k/3.07k params)\n",
            "  BoxPredictor_5 (--/4.64k params)\n",
            "    BoxPredictor_5/BoxEncodingPredictor (--/3.10k params)\n",
            "      BoxPredictor_5/BoxEncodingPredictor/biases (24, 24/24 params)\n",
            "      BoxPredictor_5/BoxEncodingPredictor/weights (1x1x128x24, 3.07k/3.07k params)\n",
            "    BoxPredictor_5/ClassPredictor (--/1.55k params)\n",
            "      BoxPredictor_5/ClassPredictor/biases (12, 12/12 params)\n",
            "      BoxPredictor_5/ClassPredictor/weights (1x1x128x12, 1.54k/1.54k params)\n",
            "  FeatureExtractor (--/5.41m params)\n",
            "    FeatureExtractor/MobilenetV1 (--/5.41m params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_0 (--/864 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_0/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_0/weights (3x3x3x32, 864/864 params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_10_depthwise (--/4.61k params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_10_depthwise/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_10_depthwise/depthwise_weights (3x3x512x1, 4.61k/4.61k params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_10_pointwise (--/262.14k params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_10_pointwise/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_10_pointwise/weights (1x1x512x512, 262.14k/262.14k params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_11_depthwise (--/4.61k params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_11_depthwise/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_11_depthwise/depthwise_weights (3x3x512x1, 4.61k/4.61k params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_11_pointwise (--/262.14k params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_11_pointwise/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_11_pointwise/weights (1x1x512x512, 262.14k/262.14k params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_12_depthwise (--/4.61k params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_12_depthwise/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_12_depthwise/depthwise_weights (3x3x512x1, 4.61k/4.61k params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_12_pointwise (--/524.29k params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_12_pointwise/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_12_pointwise/weights (1x1x512x1024, 524.29k/524.29k params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_13_depthwise (--/9.22k params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_13_depthwise/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_13_depthwise/depthwise_weights (3x3x1024x1, 9.22k/9.22k params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_13_pointwise (--/1.05m params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise/weights (1x1x1024x1024, 1.05m/1.05m params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_2_1x1_256 (--/262.14k params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_2_1x1_256/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_2_1x1_256/weights (1x1x1024x256, 262.14k/262.14k params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_3_1x1_128 (--/65.54k params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_3_1x1_128/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_3_1x1_128/weights (1x1x512x128, 65.54k/65.54k params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_4_1x1_128 (--/32.77k params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_4_1x1_128/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_4_1x1_128/weights (1x1x256x128, 32.77k/32.77k params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_5_1x1_64 (--/16.38k params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_5_1x1_64/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_5_1x1_64/weights (1x1x256x64, 16.38k/16.38k params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_2_3x3_s2_512 (--/1.18m params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_2_3x3_s2_512/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_2_3x3_s2_512/weights (3x3x256x512, 1.18m/1.18m params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_3_3x3_s2_256 (--/294.91k params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_3_3x3_s2_256/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_3_3x3_s2_256/weights (3x3x128x256, 294.91k/294.91k params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_4_3x3_s2_256 (--/294.91k params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_4_3x3_s2_256/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_4_3x3_s2_256/weights (3x3x128x256, 294.91k/294.91k params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_5_3x3_s2_128 (--/73.73k params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_5_3x3_s2_128/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_5_3x3_s2_128/weights (3x3x64x128, 73.73k/73.73k params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_1_depthwise (--/288 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_1_depthwise/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_1_depthwise/depthwise_weights (3x3x32x1, 288/288 params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_1_pointwise (--/2.05k params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_1_pointwise/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_1_pointwise/weights (1x1x32x64, 2.05k/2.05k params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_2_depthwise (--/576 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_2_depthwise/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_2_depthwise/depthwise_weights (3x3x64x1, 576/576 params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_2_pointwise (--/8.19k params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_2_pointwise/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_2_pointwise/weights (1x1x64x128, 8.19k/8.19k params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_3_depthwise (--/1.15k params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_3_depthwise/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_3_depthwise/depthwise_weights (3x3x128x1, 1.15k/1.15k params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_3_pointwise (--/16.38k params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_3_pointwise/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_3_pointwise/weights (1x1x128x128, 16.38k/16.38k params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_4_depthwise (--/1.15k params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_4_depthwise/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_4_depthwise/depthwise_weights (3x3x128x1, 1.15k/1.15k params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_4_pointwise (--/32.77k params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_4_pointwise/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_4_pointwise/weights (1x1x128x256, 32.77k/32.77k params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_5_depthwise (--/2.30k params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_5_depthwise/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_5_depthwise/depthwise_weights (3x3x256x1, 2.30k/2.30k params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_5_pointwise (--/65.54k params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_5_pointwise/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_5_pointwise/weights (1x1x256x256, 65.54k/65.54k params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_6_depthwise (--/2.30k params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_6_depthwise/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_6_depthwise/depthwise_weights (3x3x256x1, 2.30k/2.30k params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_6_pointwise (--/131.07k params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_6_pointwise/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_6_pointwise/weights (1x1x256x512, 131.07k/131.07k params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_7_depthwise (--/4.61k params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_7_depthwise/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_7_depthwise/depthwise_weights (3x3x512x1, 4.61k/4.61k params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_7_pointwise (--/262.14k params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_7_pointwise/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_7_pointwise/weights (1x1x512x512, 262.14k/262.14k params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_8_depthwise (--/4.61k params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_8_depthwise/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_8_depthwise/depthwise_weights (3x3x512x1, 4.61k/4.61k params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_8_pointwise (--/262.14k params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_8_pointwise/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_8_pointwise/weights (1x1x512x512, 262.14k/262.14k params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_9_depthwise (--/4.61k params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_9_depthwise/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_9_depthwise/depthwise_weights (3x3x512x1, 4.61k/4.61k params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_9_pointwise (--/262.14k params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_9_pointwise/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_9_pointwise/weights (1x1x512x512, 262.14k/262.14k params)\n",
            "\n",
            "======================End of Report==========================\n",
            "111 ops no flops stats due to incomplete shapes.\n",
            "Parsing Inputs...\n",
            "Incomplete shape.\n",
            "\n",
            "=========================Options=============================\n",
            "-max_depth                  10000\n",
            "-min_bytes                  0\n",
            "-min_peak_bytes             0\n",
            "-min_residual_bytes         0\n",
            "-min_output_bytes           0\n",
            "-min_micros                 0\n",
            "-min_accelerator_micros     0\n",
            "-min_cpu_micros             0\n",
            "-min_params                 0\n",
            "-min_float_ops              1\n",
            "-min_occurrence             0\n",
            "-step                       -1\n",
            "-order_by                   float_ops\n",
            "-account_type_regexes       .*\n",
            "-start_name_regexes         .*\n",
            "-trim_name_regexes          .*BatchNorm.*,.*Initializer.*,.*Regularizer.*,.*BiasAdd.*\n",
            "-show_name_regexes          .*\n",
            "-hide_name_regexes          \n",
            "-account_displayed_op_only  true\n",
            "-select                     float_ops\n",
            "-output                     stdout:\n",
            "\n",
            "==================Model Analysis Report======================\n",
            "Incomplete shape.\n",
            "\n",
            "Doc:\n",
            "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
            "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
            "\n",
            "Profile:\n",
            "node name | # float_ops\n",
            "_TFProfRoot (--/17.63k flops)\n",
            "  MultipleGridAnchorGenerator/sub (2.17k/2.17k flops)\n",
            "  MultipleGridAnchorGenerator/add_2 (2.17k/2.17k flops)\n",
            "  MultipleGridAnchorGenerator/mul_20 (2.17k/2.17k flops)\n",
            "  MultipleGridAnchorGenerator/mul_19 (2.17k/2.17k flops)\n",
            "  MultipleGridAnchorGenerator/mul_27 (1.20k/1.20k flops)\n",
            "  MultipleGridAnchorGenerator/sub_1 (1.20k/1.20k flops)\n",
            "  MultipleGridAnchorGenerator/add_5 (1.20k/1.20k flops)\n",
            "  MultipleGridAnchorGenerator/mul_28 (1.20k/1.20k flops)\n",
            "  MultipleGridAnchorGenerator/mul_21 (1.08k/1.08k flops)\n",
            "  MultipleGridAnchorGenerator/mul_29 (600/600 flops)\n",
            "  MultipleGridAnchorGenerator/add_8 (300/300 flops)\n",
            "  MultipleGridAnchorGenerator/mul_36 (300/300 flops)\n",
            "  MultipleGridAnchorGenerator/sub_2 (300/300 flops)\n",
            "  MultipleGridAnchorGenerator/mul_35 (300/300 flops)\n",
            "  MultipleGridAnchorGenerator/mul_37 (150/150 flops)\n",
            "  MultipleGridAnchorGenerator/sub_3 (108/108 flops)\n",
            "  MultipleGridAnchorGenerator/mul_44 (108/108 flops)\n",
            "  MultipleGridAnchorGenerator/mul_43 (108/108 flops)\n",
            "  MultipleGridAnchorGenerator/add_11 (108/108 flops)\n",
            "  MultipleGridAnchorGenerator/mul_45 (54/54 flops)\n",
            "  MultipleGridAnchorGenerator/sub_4 (48/48 flops)\n",
            "  MultipleGridAnchorGenerator/add_14 (48/48 flops)\n",
            "  MultipleGridAnchorGenerator/mul_51 (48/48 flops)\n",
            "  MultipleGridAnchorGenerator/mul_52 (48/48 flops)\n",
            "  MultipleGridAnchorGenerator/mul_53 (24/24 flops)\n",
            "  MultipleGridAnchorGenerator/add (19/19 flops)\n",
            "  MultipleGridAnchorGenerator/mul_18 (19/19 flops)\n",
            "  MultipleGridAnchorGenerator/mul_17 (19/19 flops)\n",
            "  MultipleGridAnchorGenerator/add_1 (19/19 flops)\n",
            "  MultipleGridAnchorGenerator/mul_59 (12/12 flops)\n",
            "  MultipleGridAnchorGenerator/mul_60 (12/12 flops)\n",
            "  MultipleGridAnchorGenerator/sub_5 (12/12 flops)\n",
            "  MultipleGridAnchorGenerator/add_17 (12/12 flops)\n",
            "  MultipleGridAnchorGenerator/add_4 (10/10 flops)\n",
            "  MultipleGridAnchorGenerator/add_3 (10/10 flops)\n",
            "  MultipleGridAnchorGenerator/mul_26 (10/10 flops)\n",
            "  MultipleGridAnchorGenerator/mul_25 (10/10 flops)\n",
            "  MultipleGridAnchorGenerator/mul_38 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_54 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_19 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_18 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_17 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_16 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_39 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_40 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_15 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_61 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_46 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_47 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_48 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_56 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_55 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_32 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_31 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_30 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_22 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_24 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_23 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_33 (5/5 flops)\n",
            "  MultipleGridAnchorGenerator/add_6 (5/5 flops)\n",
            "  MultipleGridAnchorGenerator/add_7 (5/5 flops)\n",
            "  MultipleGridAnchorGenerator/mul_34 (5/5 flops)\n",
            "  MultipleGridAnchorGenerator/mul_41 (3/3 flops)\n",
            "  MultipleGridAnchorGenerator/mul_42 (3/3 flops)\n",
            "  MultipleGridAnchorGenerator/add_9 (3/3 flops)\n",
            "  MultipleGridAnchorGenerator/add_10 (3/3 flops)\n",
            "  MultipleGridAnchorGenerator/mul_16 (3/3 flops)\n",
            "  MultipleGridAnchorGenerator/mul_15 (3/3 flops)\n",
            "  MultipleGridAnchorGenerator/mul_14 (3/3 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_14 (3/3 flops)\n",
            "  MultipleGridAnchorGenerator/add_12 (2/2 flops)\n",
            "  MultipleGridAnchorGenerator/add_13 (2/2 flops)\n",
            "  MultipleGridAnchorGenerator/mul_50 (2/2 flops)\n",
            "  MultipleGridAnchorGenerator/mul_49 (2/2 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_7 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_6 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_8 (1/1 flops)\n",
            "  Preprocessor/map/while/add (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/Minimum (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_9 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_1 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_1 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_5 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_4 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_3 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_2 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_1 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/add (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/SortByField_1/Equal (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/SortByField/Equal (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_17 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_14 (1/1 flops)\n",
            "  Preprocessor/map/while/add_1 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_19 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_2 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_16 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_3 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_4 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_5 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_6 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_7 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_8 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_15 (1/1 flops)\n",
            "  Preprocessor/map/while/Less_1 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_13 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_18 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_12 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_11 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_10 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_9 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/add (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/add_1 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/ones/Less (1/1 flops)\n",
            "  Preprocessor/map/while/Less (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_1 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_58 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_57 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_5 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_4 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_3 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_2 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_13 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_12 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_11 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_10 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_6 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/assert_equal/Equal (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/add_23 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/add_22 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/add_21 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/add_20 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/add_19 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/add_18 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/add_16 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/add_15 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_2 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Greater (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/Less_1 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/Less (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_9 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_8 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_7 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_6 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_5 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_4 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_3 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_13 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_12 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_11 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_10 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_1 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_9 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_8 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_7 (1/1 flops)\n",
            "\n",
            "======================End of Report==========================\n",
            "W0727 12:24:44.572827 140429546862464 deprecation_wrapper.py:119] From /content/models/research/object_detection/exporter.py:411: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "2019-07-27 12:24:45.394441: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1\n",
            "2019-07-27 12:24:45.444929: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-27 12:24:45.445341: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2019-07-27 12:24:45.445620: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
            "2019-07-27 12:24:45.446900: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
            "2019-07-27 12:24:45.448105: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\n",
            "2019-07-27 12:24:45.448498: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\n",
            "2019-07-27 12:24:45.450731: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2019-07-27 12:24:45.464345: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2019-07-27 12:24:45.478498: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
            "2019-07-27 12:24:45.478634: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-27 12:24:45.479113: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-27 12:24:45.479492: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
            "2019-07-27 12:24:45.488347: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200000000 Hz\n",
            "2019-07-27 12:24:45.488574: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x17bf800 executing computations on platform Host. Devices:\n",
            "2019-07-27 12:24:45.488605: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\n",
            "2019-07-27 12:24:45.621177: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-27 12:24:45.621729: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x17bf640 executing computations on platform CUDA. Devices:\n",
            "2019-07-27 12:24:45.621760: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "2019-07-27 12:24:45.622055: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-27 12:24:45.622437: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2019-07-27 12:24:45.622508: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
            "2019-07-27 12:24:45.622538: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
            "2019-07-27 12:24:45.622560: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\n",
            "2019-07-27 12:24:45.622583: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\n",
            "2019-07-27 12:24:45.622605: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2019-07-27 12:24:45.622626: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2019-07-27 12:24:45.622648: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
            "2019-07-27 12:24:45.622730: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-27 12:24:45.623167: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-27 12:24:45.623503: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
            "2019-07-27 12:24:45.623572: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
            "2019-07-27 12:24:45.624601: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-07-27 12:24:45.624631: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 \n",
            "2019-07-27 12:24:45.624652: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N \n",
            "2019-07-27 12:24:45.624999: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-27 12:24:45.625424: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-27 12:24:45.625820: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:40] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2019-07-27 12:24:45.625866: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14202 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "W0727 12:24:45.626556 140429546862464 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "I0727 12:24:45.627929 140429546862464 saver.py:1280] Restoring parameters from training/model.ckpt-30000\n",
            "2019-07-27 12:24:47.688099: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-27 12:24:47.688553: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2019-07-27 12:24:47.688641: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
            "2019-07-27 12:24:47.688669: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
            "2019-07-27 12:24:47.688706: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\n",
            "2019-07-27 12:24:47.688728: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\n",
            "2019-07-27 12:24:47.688753: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2019-07-27 12:24:47.688776: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2019-07-27 12:24:47.688819: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
            "2019-07-27 12:24:47.688910: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-27 12:24:47.689352: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-27 12:24:47.689713: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
            "2019-07-27 12:24:47.689756: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-07-27 12:24:47.689802: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 \n",
            "2019-07-27 12:24:47.689818: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N \n",
            "2019-07-27 12:24:47.690127: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-27 12:24:47.690564: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-27 12:24:47.690963: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14202 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "I0727 12:24:47.692423 140429546862464 saver.py:1280] Restoring parameters from training/model.ckpt-30000\n",
            "W0727 12:24:48.118048 140429546862464 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/tools/freeze_graph.py:233: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
            "W0727 12:24:48.118309 140429546862464 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/graph_util_impl.py:270: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
            "I0727 12:24:48.388280 140429546862464 graph_util_impl.py:311] Froze 199 variables.\n",
            "I0727 12:24:48.473463 140429546862464 graph_util_impl.py:364] Converted 199 variables to const ops.\n",
            "2019-07-27 12:24:48.605106: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-27 12:24:48.605552: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2019-07-27 12:24:48.605698: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
            "2019-07-27 12:24:48.605750: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
            "2019-07-27 12:24:48.605779: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\n",
            "2019-07-27 12:24:48.605825: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\n",
            "2019-07-27 12:24:48.605858: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2019-07-27 12:24:48.605888: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2019-07-27 12:24:48.605917: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
            "2019-07-27 12:24:48.606008: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-27 12:24:48.606426: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-27 12:24:48.606805: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
            "2019-07-27 12:24:48.606925: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-07-27 12:24:48.606959: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 \n",
            "2019-07-27 12:24:48.606970: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N \n",
            "2019-07-27 12:24:48.607270: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-27 12:24:48.607685: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-27 12:24:48.608062: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14202 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "W0727 12:24:48.989381 140429546862464 deprecation_wrapper.py:119] From /content/models/research/object_detection/exporter.py:288: The name tf.saved_model.builder.SavedModelBuilder is deprecated. Please use tf.compat.v1.saved_model.builder.SavedModelBuilder instead.\n",
            "\n",
            "W0727 12:24:48.989865 140429546862464 deprecation.py:323] From /content/models/research/object_detection/exporter.py:291: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
            "W0727 12:24:48.990353 140429546862464 deprecation_wrapper.py:119] From /content/models/research/object_detection/exporter.py:297: The name tf.saved_model.signature_def_utils.build_signature_def is deprecated. Please use tf.compat.v1.saved_model.signature_def_utils.build_signature_def instead.\n",
            "\n",
            "W0727 12:24:48.990499 140429546862464 deprecation_wrapper.py:119] From /content/models/research/object_detection/exporter.py:300: The name tf.saved_model.signature_constants.PREDICT_METHOD_NAME is deprecated. Please use tf.saved_model.PREDICT_METHOD_NAME instead.\n",
            "\n",
            "W0727 12:24:48.990686 140429546862464 deprecation_wrapper.py:119] From /content/models/research/object_detection/exporter.py:305: The name tf.saved_model.tag_constants.SERVING is deprecated. Please use tf.saved_model.SERVING instead.\n",
            "\n",
            "W0727 12:24:48.990828 140429546862464 deprecation_wrapper.py:119] From /content/models/research/object_detection/exporter.py:307: The name tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY is deprecated. Please use tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY instead.\n",
            "\n",
            "I0727 12:24:48.991123 140429546862464 builder_impl.py:636] No assets to save.\n",
            "I0727 12:24:48.991205 140429546862464 builder_impl.py:456] No assets to write.\n",
            "I0727 12:24:49.241883 140429546862464 builder_impl.py:421] SavedModel written to: ./fine_tuned_model/saved_model/saved_model.pb\n",
            "W0727 12:24:49.267150 140429546862464 deprecation_wrapper.py:119] From /content/models/research/object_detection/utils/config_util.py:188: The name tf.gfile.Open is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "I0727 12:24:49.267348 140429546862464 config_util.py:190] Writing pipeline config file to ./fine_tuned_model/pipeline.config\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "znwq5TqlZJOd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "846148f0-0471-4111-92e1-bfd37d6c3979"
      },
      "source": [
        "!ls {output_directory}"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "checkpoint\t\t\tmodel.ckpt.index  saved_model\n",
            "frozen_inference_graph.pb\tmodel.ckpt.meta\n",
            "model.ckpt.data-00000-of-00001\tpipeline.config\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "847rb3bcZO_N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "pb_fname = os.path.join(os.path.abspath(output_directory), \"frozen_inference_graph.pb\")\n",
        "assert os.path.isfile(pb_fname), '`{}` not exist'.format(pb_fname)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYtsDHySZVR9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "008eb75c-2a1a-4f04-fd10-276c2073e338"
      },
      "source": [
        "!ls -alh {pb_fname}"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-rw-r--r-- 1 root root 22M Jul 27 12:24 /content/models/research/fine_tuned_model/frozen_inference_graph.pb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vWABrZXPZi7O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 575
        },
        "outputId": "8465bc88-95e1-4d9c-feb7-06f904e5a56d"
      },
      "source": [
        "# Install the PyDrive wrapper & import libraries.\n",
        "# This only needs to be done once in a notebook.\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "\n",
        "# Authenticate and create the PyDrive client.\n",
        "# This only needs to be done once in a notebook.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "fname = os.path.basename(pb_fname)\n",
        "# Create & upload a text file.\n",
        "uploaded = drive.CreateFile({'title': fname})\n",
        "uploaded.SetContentFile(pb_fname)\n",
        "uploaded.Upload()\n",
        "print('Uploaded file with ID {}'.format(uploaded.get('id')))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K     |▎                               | 10kB 21.3MB/s eta 0:00:01\r\u001b[K     |▋                               | 20kB 26.5MB/s eta 0:00:01\r\u001b[K     |█                               | 30kB 31.1MB/s eta 0:00:01\r\u001b[K     |█▎                              | 40kB 35.3MB/s eta 0:00:01\r\u001b[K     |█▋                              | 51kB 38.9MB/s eta 0:00:01\r\u001b[K     |██                              | 61kB 42.9MB/s eta 0:00:01\r\u001b[K     |██▎                             | 71kB 41.3MB/s eta 0:00:01\r\u001b[K     |██▋                             | 81kB 40.5MB/s eta 0:00:01\r\u001b[K     |███                             | 92kB 42.5MB/s eta 0:00:01\r\u001b[K     |███▎                            | 102kB 40.7MB/s eta 0:00:01\r\u001b[K     |███▋                            | 112kB 40.7MB/s eta 0:00:01\r\u001b[K     |████                            | 122kB 40.7MB/s eta 0:00:01\r\u001b[K     |████▎                           | 133kB 40.7MB/s eta 0:00:01\r\u001b[K     |████▋                           | 143kB 40.7MB/s eta 0:00:01\r\u001b[K     |█████                           | 153kB 40.7MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 163kB 40.7MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 174kB 40.7MB/s eta 0:00:01\r\u001b[K     |██████                          | 184kB 40.7MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 194kB 40.7MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 204kB 40.7MB/s eta 0:00:01\r\u001b[K     |███████                         | 215kB 40.7MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 225kB 40.7MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 235kB 40.7MB/s eta 0:00:01\r\u001b[K     |████████                        | 245kB 40.7MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 256kB 40.7MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 266kB 40.7MB/s eta 0:00:01\r\u001b[K     |█████████                       | 276kB 40.7MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 286kB 40.7MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 296kB 40.7MB/s eta 0:00:01\r\u001b[K     |██████████                      | 307kB 40.7MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 317kB 40.7MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 327kB 40.7MB/s eta 0:00:01\r\u001b[K     |███████████                     | 337kB 40.7MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 348kB 40.7MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 358kB 40.7MB/s eta 0:00:01\r\u001b[K     |████████████                    | 368kB 40.7MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 378kB 40.7MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 389kB 40.7MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 399kB 40.7MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 409kB 40.7MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 419kB 40.7MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 430kB 40.7MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 440kB 40.7MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 450kB 40.7MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 460kB 40.7MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 471kB 40.7MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 481kB 40.7MB/s eta 0:00:01\r\u001b[K     |████████████████                | 491kB 40.7MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 501kB 40.7MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 512kB 40.7MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 522kB 40.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 532kB 40.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 542kB 40.7MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 552kB 40.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 563kB 40.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 573kB 40.7MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 583kB 40.7MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 593kB 40.7MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 604kB 40.7MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 614kB 40.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 624kB 40.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 634kB 40.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 645kB 40.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 655kB 40.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 665kB 40.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 675kB 40.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 686kB 40.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 696kB 40.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 706kB 40.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 716kB 40.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 727kB 40.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 737kB 40.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 747kB 40.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 757kB 40.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 768kB 40.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 778kB 40.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 788kB 40.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 798kB 40.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 808kB 40.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 819kB 40.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 829kB 40.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 839kB 40.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 849kB 40.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 860kB 40.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 870kB 40.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 880kB 40.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 890kB 40.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 901kB 40.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 911kB 40.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 921kB 40.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 931kB 40.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 942kB 40.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 952kB 40.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 962kB 40.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 972kB 40.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 983kB 40.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 993kB 40.7MB/s \n",
            "\u001b[?25h  Building wheel for PyDrive (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0727 12:28:24.382980 140635306858368 __init__.py:44] file_cache is unavailable when using oauth2client >= 4.0.0 or google-auth\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/googleapiclient/discovery_cache/__init__.py\", line 36, in autodetect\n",
            "    from google.appengine.api import memcache\n",
            "ModuleNotFoundError: No module named 'google.appengine'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/googleapiclient/discovery_cache/file_cache.py\", line 33, in <module>\n",
            "    from oauth2client.contrib.locked_file import LockedFile\n",
            "ModuleNotFoundError: No module named 'oauth2client.contrib.locked_file'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/googleapiclient/discovery_cache/file_cache.py\", line 37, in <module>\n",
            "    from oauth2client.locked_file import LockedFile\n",
            "ModuleNotFoundError: No module named 'oauth2client.locked_file'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/googleapiclient/discovery_cache/__init__.py\", line 41, in autodetect\n",
            "    from . import file_cache\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/googleapiclient/discovery_cache/file_cache.py\", line 41, in <module>\n",
            "    'file_cache is unavailable when using oauth2client >= 4.0.0 or google-auth')\n",
            "ImportError: file_cache is unavailable when using oauth2client >= 4.0.0 or google-auth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Uploaded file with ID 1U84j7uMpPpxHYz5jw6KhY-z-tLG-lk_r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JLQgy6jqZ5Rg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "files.download(pb_fname)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q59R_54Yae5G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "files.download(label_map_pbtxt_fname)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}